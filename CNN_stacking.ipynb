{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-stacking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPforu3mKe+EQyr/oi9FFbn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rokia88/EMV/blob/master/CNN_stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sSiqul52E3wm",
        "outputId": "a695ac25-e4f8-47af-b851-2c55c6b0cabf"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from pprint import pprint\n",
        "from urllib.parse import unquote\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "import re\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from keras.utils import plot_model,to_categorical\n",
        "# Scikit learn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "# Word2vec\n",
        "import gensim\n",
        "import multiprocessing\n",
        "# Keras\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.constraints import maxnorm\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import keras_metrics\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from pandas import DataFrame\n",
        "from os import makedirs\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn import metrics\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "logdir = \"./model2logs\"\n",
        "datasetfile = './csic3.csv'\n",
        "sgd = SGD(lr=0.01,momentum=0.9,decay=0.003, nesterov=True)\n",
        "adam = Adam()\n",
        "#sgd = SGD()\n",
        "word2vec_filepath = './word2vec1.model'\n",
        "OPTIMIZER = adam\n",
        "BATCH_SIZE = 128\n",
        "NB_EPOCH = 20\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_models,run):\n",
        "    all_models = list()\n",
        "    for i in range(n_models):\n",
        "        # define filename for this ensemble\n",
        "        filename = 'models/model_' + str(i + 1) + str(run)+'.h5'\n",
        "        # load model from file\n",
        "        model = load_model(filename)\n",
        "        # add to list of members\n",
        "        all_models.append(model)\n",
        "        print('>loaded %s' % filename)\n",
        "    return all_models\n",
        "\n",
        "# define stacked model from multiple member input models\n",
        "def define_stacked_model(members,run):\n",
        "    # update all layers in all models to not be trainable\n",
        "    for i in range(len(members)):\n",
        "        model = members[i]\n",
        "        for layer in model.layers:\n",
        "            # make not trainable\n",
        "            layer.trainable = False\n",
        "            # rename to avoid 'unique layer name' issue\n",
        "            layer._name = 'ensemble_' + str(i+1) + str(run)+'_' + layer.name\n",
        "    # define multi-headed input\n",
        "    ensemble_visible = [model.input for model in members]\n",
        "    # concatenate merge output from each model\n",
        "    ensemble_outputs = [model.output for model in members]\n",
        "\n",
        "    merge = tf.keras.layers.concatenate(ensemble_outputs)\n",
        "    hidden = tf.keras.layers.Dense(10, activation='relu')(merge)\n",
        "    output = tf.keras.layers.Dense(2, activation='softmax')(hidden)\n",
        "    model = tf.keras.Model(inputs=ensemble_visible, outputs=output)\n",
        "    # plot graph of ensemble\n",
        "    #plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
        "    print(model.summary())\n",
        "    # compile\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# init callback class\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "        Callback to print loss after each epoch\n",
        "        \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "    \n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss\n",
        "\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "    # load the dataset as a pandas DataFrame\n",
        "    dataset = read_csv(filename,names=['URL','label'], sep=';',header=0)\n",
        "    # split into input (X) and output (y) variables\n",
        "    X = dataset\n",
        "    y = dataset[['label']]\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def URLDECODE(payload):\n",
        "    payload = payload.lower()\n",
        "    while True:\n",
        "        test = payload\n",
        "        payload = unquote(payload)\n",
        "        if test == payload:\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "    payload, num = re.subn(r'\\d+', \"0\", payload)\n",
        "    \n",
        "    payload, num = re.subn(r'(http|https)://[a-zA-Z0-9\\.@&/#!#\\?]+', \"http://u\", payload)\n",
        "    \n",
        "    r = '''\n",
        "        (?x)[\\w\\.]+?\\(\n",
        "        |\\)\n",
        "        |\"\\w+?\"\n",
        "        |'\\w+?'\n",
        "        |http://\\w\n",
        "        |</\\w+>\n",
        "        |<\\w+>\n",
        "        |<\\w+\n",
        "        |\\w+=\n",
        "        |>\n",
        "        |[\\w\\.]+\n",
        "        '''\n",
        "    return nltk.regexp_tokenize(payload, r)\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "    #read line by line\n",
        "    test_words = []\n",
        "    train_words = []\n",
        "    max_length = 0\n",
        "    X_train_enc = X_train.tolist()\n",
        "    X_test_enc = X_test.tolist()\n",
        "    for x in X_train_enc:\n",
        "        request = listToString(x)\n",
        "        words= URLDECODE(request)\n",
        "        train_words.append(words)\n",
        "    for x in X_test_enc:\n",
        "        request = listToString(x)\n",
        "        words= URLDECODE(request)\n",
        "        test_words.append(words)\n",
        "    return train_words,test_words\n",
        "\n",
        "def listToString(s): \n",
        "    # initialize an empty string\n",
        "    str1 = \"\"\n",
        "    # traverse in the string\n",
        "    for ele in s:\n",
        "        str1 += ele\n",
        "    # return string\n",
        "    return str1\n",
        "\n",
        "def create_model(embedding_matrix,vocab_size,kernelsize):\n",
        "    # define the model\n",
        "    # input layer\n",
        "    initializer = tf.keras.initializers.HeNormal()\n",
        "    input = tf.keras.Input(shape=(20,))\n",
        "    embd =  tf.keras.layers.Embedding(vocab_size,128,weights=[embedding_matrix],input_length=20,trainable=False)(input)\n",
        "    conv1 = tf.keras.layers.Conv1D(300,kernel_size=kernelsize,activation=tf.nn.relu,kernel_initializer=initializer)(embd)\n",
        "    conv1 = tf.keras.layers.LayerNormalization()(conv1)\n",
        "    conv1 = tf.keras.layers.Dropout(0.3)(conv1)\n",
        "    pool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
        "    flat1 = tf.keras.layers.Flatten()(pool1)\n",
        "    dense = tf.keras.layers.Dense(1024, activation=tf.nn.relu,kernel_initializer=initializer)(flat1)\n",
        "    dense = tf.keras.layers.LayerNormalization()(dense)\n",
        "    dense = tf.keras.layers.Dropout(0.3)(dense)\n",
        "    output = tf.keras.layers.Dense(2, activation=tf.nn.softmax)(dense)\n",
        "    model = tf.keras.Model(inputs=[input], outputs=output)\n",
        "    \n",
        "    # summarize the model\n",
        "    print(model.summary())\n",
        "    tf.keras.utils.plot_model(model, to_file='shared_input_layer.png')\n",
        "    # compile the model\n",
        "    model.compile(optimizer=OPTIMIZER, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def prepare_targets(y_train,y_val, y_test):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(y_train)\n",
        "    y_train_enc = le.transform(y_train)\n",
        "    y_test_enc = le.transform(y_test)\n",
        "    y_val_enc = le.transform(y_val)\n",
        "    print(y_test_enc[0])\n",
        "    y_train_enc = to_categorical(y_train_enc, num_classes=2)\n",
        "    y_test_enc = to_categorical(y_test_enc, num_classes=2)\n",
        "    #y_val_enc = to_categorical(y_val_enc, num_classes=2)\n",
        "    #print(y_test_enc[0])\n",
        "    return y_train_enc, y_val_enc, y_test_enc\n",
        "\n",
        "def standardize_data(x_train,x_test,x_val):\n",
        "    trans = StandardScaler()\n",
        "    trans.fit(x_train)\n",
        "    x_train_std = trans.transform(x_train)\n",
        "    x_test_std = trans.transform(x_test)\n",
        "    x_val_std = trans.transform(x_val)\n",
        "    return x_train_std,x_test_std,x_val_std\n",
        "\n",
        "# fit a stacked model\n",
        "def fit_stacked_model(model, inputX, inputy):\n",
        "    # prepare input data\n",
        "    X = [inputX for _ in range(len(model.input))]\n",
        "    print(X)\n",
        "    # fit model\n",
        "    history = model.fit(X,inputy,epochs=NB_EPOCH,batch_size=BATCH_SIZE)\n",
        "    return history\n",
        "\n",
        "# make a prediction with a stacked model\n",
        "def predict_stacked_model(model, inputX):\n",
        "    # prepare input data\n",
        "    X = [inputX for _ in range(len(model.input))]\n",
        "    # make prediction\n",
        "    return model.predict(X, verbose=0)\n",
        "\n",
        "def texts_to_sequences(s_tokens,word_index):\n",
        "    result = []\n",
        "    l2 = []\n",
        "    for s in s_tokens:\n",
        "        for token in s:\n",
        "            if word_index.get(token) is not None:\n",
        "                l2.append(word_index.get(token))\n",
        "            else:\n",
        "                l2.append(0)\n",
        "        result.append(l2)\n",
        "        l2 = []\n",
        "    print(result[0],result[1])\n",
        "    if(len(result)==0):\n",
        "        print(\"result empty\")\n",
        "    return result\n",
        "\n",
        "X, y = load_dataset(datasetfile)\n",
        "run = 0\n",
        "loss_avg = 0\n",
        "acc_avg = 0\n",
        "prec_avg = 0\n",
        "reca_avg = 0\n",
        "acc_min = 1\n",
        "acc_max = 0\n",
        "fig1, axs1 = plt.subplots(5, sharey=True)\n",
        "fig2, axs2 = plt.subplots(5, sharey=True)\n",
        "fig1.suptitle('Loss')\n",
        "fig2.suptitle('Accuracy')\n",
        "makedirs('models')\n",
        "MAX_RUNS = 5\n",
        "while run < MAX_RUNS:\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.33,stratify=y,shuffle= True)\n",
        "        # prepare output data\n",
        "        #y_train_enc1, y_test_enc= prepare_targets(y_train1, y_test)\n",
        "        X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.16,stratify=y_temp,shuffle= True)\n",
        "        # prepare output data\n",
        "        y_train_enc, y_val_enc, y_test_enc= prepare_targets(y_train, y_val,y_test)\n",
        "        print(X_train.head())\n",
        "        print(X_train.shape)\n",
        "        print(X_train.label.value_counts())\n",
        "        print(X_test.head())\n",
        "        print(X_test.shape)\n",
        "        print(X_test.label.value_counts())\n",
        "        print(X_val.head())\n",
        "        print(X_val.shape)\n",
        "        print(X_val.label.value_counts())\n",
        "        #split text in tokens\n",
        "        #print(X_train.values[0:5,:])\n",
        "        sentences = [URLDECODE(listToString(text)) for text in X.values[:,:-1]]\n",
        "#        #print(sentences)\n",
        "        model = gensim.models.Word2Vec(min_count=1, window=2,size=128,alpha=0.1,min_alpha=0.0007,workers=multiprocessing.cpu_count())\n",
        "        model.build_vocab(sentences)\n",
        "        model.train(sentences, total_examples=model.corpus_count, epochs=30,compute_loss = True,callbacks=[callback()])\n",
        "        #model = gensim.models.Word2Vec.load(word2vec_filepath)\n",
        "        words = list(model.wv.vocab)\n",
        "        print(words[5])\n",
        "        print(\"Vocabulary size: %i\" % len(words))\n",
        "        sentences_training = []\n",
        "        for text in X_train.values[:,:-1]:\n",
        "            l1 = URLDECODE(listToString(text))\n",
        "            for u in l1:\n",
        "                sentences_training.append(u)\n",
        "        # creating a dictionary of vocab with index\n",
        "        #vocab_of_text = list(enumerate(sentences_training, 1))\n",
        "        #print(len(vocab_of_text))\n",
        "        vocab = sorted(set(sentences_training))\n",
        "        vocab = list(enumerate(vocab, 1))\n",
        "        print(len(vocab))\n",
        "        # putting the index first\n",
        "        indexed_vocab = {k:v for v,k in dict(vocab).items()}\n",
        "        print(len(indexed_vocab))\n",
        "        #tokenizer.fit_on_texts(sentences[0],sentences[1])\n",
        "        #print(tokenizer.word_index)\n",
        "        #num_words = len(tokenizer.word_index) + 1\n",
        "        # print(\"Number of unique words: %i\" % num_words)\n",
        "        print(\"Create Embedding matrix\")\n",
        "        #word_index = tokenizer.word_index\n",
        "        vocab_size = len(words) + 1\n",
        "        embedding_matrix = np.zeros((len(words) + 1, 128))\n",
        "        for word, idx in indexed_vocab.items():\n",
        "            if word in words:\n",
        "                embedding_vector = model.wv.get_vector(word)\n",
        "                if embedding_vector is not None:\n",
        "                    embedding_matrix[idx] = model.wv[word]\n",
        "        print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))\n",
        "        print(\"Build Keras model\")\n",
        "        sentences_train = [URLDECODE(listToString(text)) for text in X_train.values[:,:-1]]\n",
        "        x_train = keras.preprocessing.sequence.pad_sequences(texts_to_sequences(sentences_train,indexed_vocab),maxlen=20)\n",
        "        sentences_val = [URLDECODE(listToString(text)) for text in X_val.values[:,:-1]]\n",
        "        x_val = keras.preprocessing.sequence.pad_sequences(texts_to_sequences(sentences_val,indexed_vocab),maxlen=20)\n",
        "        sentences_test = [URLDECODE(listToString(text)) for text in X_test.values[:,:-1]]\n",
        "        x_test = keras.preprocessing.sequence.pad_sequences(texts_to_sequences(sentences_test,indexed_vocab),maxlen=20)\n",
        "        print('x_train shape: %s' % str(x_train.shape))\n",
        "        print(x_train[0,:])\n",
        "        print('x_val shape: %s' % str(x_val.shape))\n",
        "        print(x_val[0,:])\n",
        "        print('x_test shape: %s' % str(x_test.shape))\n",
        "        print(x_test[0,:])\n",
        "        logdir= logdir+str(run)\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "        print(np.any(np.isnan(x_train)))\n",
        "        print(np.any(np.isnan(y_train_enc)))\n",
        "        print(np.any(np.isnan(x_val)))\n",
        "        print(np.any(np.isnan(y_val_enc)))\n",
        "        print(np.any(np.isnan(x_test)))\n",
        "        print(np.any(np.isnan(y_test_enc)))\n",
        "        k_model1 = create_model(embedding_matrix,vocab_size,2)\n",
        "        history1 = k_model1.fit(x=x_train,verbose=2,\n",
        "                y=y_train_enc,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                epochs=NB_EPOCH)\n",
        "        filename = 'models/model_' + str(1) + str(run)+'.h5'\n",
        "        k_model1.save(filename)\n",
        "        print('>Saved %s' % filename)\n",
        "        axs1[0].plot(history1.history['loss'], label=str(run))\n",
        "        axs2[0].plot(history1.history['accuracy'], label=str(run))\n",
        "        axs1[0].set_xlabel('loss-model1')\n",
        "        axs2[0].set_xlabel('accuracy-model1')\n",
        "        k_model2 = create_model(embedding_matrix,vocab_size,3)\n",
        "        history2 = k_model2.fit(x=x_train,verbose=2,\n",
        "                     y=y_train_enc,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     epochs=NB_EPOCH)\n",
        "        filename = 'models/model_' + str(2) + str(run)+'.h5'\n",
        "        k_model2.save(filename)\n",
        "        print('>Saved %s' % filename)\n",
        "        axs1[1].plot(history2.history['loss'], label=str(run))\n",
        "        axs2[1].plot(history2.history['accuracy'], label=str(run))\n",
        "        axs1[1].set_xlabel('loss-model2')\n",
        "        axs2[1].set_xlabel('accuracy-model2')\n",
        "        k_model3 = create_model(embedding_matrix,vocab_size,4)\n",
        "        history3 = k_model3.fit(x=x_train,verbose=2,\n",
        "                     y=y_train_enc,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     epochs=NB_EPOCH)\n",
        "        filename = 'models/model_' + str(3) + str(run)+'.h5'\n",
        "        k_model3.save(filename)\n",
        "        print('>Saved %s' % filename)\n",
        "        axs1[2].plot(history3.history['loss'], label=str(run))\n",
        "        axs2[2].plot(history3.history['accuracy'], label=str(run))\n",
        "        axs1[2].set_xlabel('loss-model3')\n",
        "        axs2[2].set_xlabel('accuracy-model3')\n",
        "        k_model4 = create_model(embedding_matrix,vocab_size,5)\n",
        "        history4 = k_model4.fit(x=x_train,verbose=2,\n",
        "                     y=y_train_enc,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     epochs=NB_EPOCH)\n",
        "        filename = 'models/model_' + str(4) + str(run)+'.h5'\n",
        "        k_model4.save(filename)\n",
        "        print('>Saved %s' % filename)\n",
        "        axs1[3].plot(history4.history['loss'], label=str(run))\n",
        "        axs2[3].plot(history4.history['accuracy'], label=str(run))\n",
        "        axs1[3].set_xlabel('loss-model4')\n",
        "        axs2[3].set_xlabel('accuracy-model4')\n",
        "        members = load_all_models(4,run)\n",
        "        stacked_model = define_stacked_model(members,run)\n",
        "        history5 = fit_stacked_model(stacked_model,x_test,y_test_enc)\n",
        "        axs1[4].plot(history5.history['loss'], label=str(run))\n",
        "        axs2[4].plot(history5.history['accuracy'], label=str(run))\n",
        "        axs1[4].set_xlabel('loss-StackedModel')\n",
        "        axs2[4].set_xlabel('accuracy-StackedModel')\n",
        "        yhat = predict_stacked_model(stacked_model, x_val)\n",
        "        #print(yhat)\n",
        "        loss = metrics.log_loss(y_val_enc, yhat)\n",
        "        yhat = np.argmax(yhat, axis=1)\n",
        "        #print(yhat)\n",
        "        #print(y_val_enc)\n",
        "        accuracy = metrics.accuracy_score(y_val_enc, yhat)\n",
        "        print(classification_report(y_val_enc, yhat))\n",
        "        print('RUN:%f'%(run))\n",
        "        print('Accuracy: %f, loss:%f' % (accuracy*100,loss))\n",
        "        acc_avg += accuracy\n",
        "        loss_avg += loss\n",
        "        if (accuracy<acc_min):\n",
        "            acc_min = accuracy\n",
        "        if (accuracy>acc_max):\n",
        "            acc_max= accuracy\n",
        "        run = run +1\n",
        "acc_avg = acc_avg/MAX_RUNS\n",
        "loss_avg = loss_avg/MAX_RUNS\n",
        "print('Max Accuracy: %f,Min Accuracy: %f,Avg Accuracy: %f, Avg loss:%f' % (acc_max*100,acc_min*100,acc_avg*100,loss_avg))\n",
        "fig1.show()\n",
        "fig2.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(223585, 2)\n",
            "(223585, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "                                                      URL label\n",
            "108656  POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "1051    GET http://localhost:8080/tienda1/publico/aute...  anom\n",
            "203448  POST http://localhost:8080/tienda1/publico/reg...  norm\n",
            "121054  GET http://localhost:8080/tienda1/miembros/edi...  norm\n",
            "144054  GET http://localhost:8080/tienda1/miembros/edi...  norm\n",
            "(149801, 2)\n",
            "anom    80121\n",
            "norm    69680\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "207015  POST http://localhost:8080/tienda1/publico/reg...  norm\n",
            "175103  GET http://localhost:8080/tienda1/publico/regi...  norm\n",
            "9933    GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "28599   GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "188067  POST http://localhost:8080/tienda1/publico/pag...  norm\n",
            "(61978, 2)\n",
            "anom    33149\n",
            "norm    28829\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "44518   GET http://localhost:8080/tienda1/global/estil...  anom\n",
            "54856   GET http://localhost:8080/tienda1/publico/anad...  anom\n",
            "77264   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "43369   GET http://localhost:8080/tienda1/publico/paga...  anom\n",
            "218077  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "(11806, 2)\n",
            "anom    6315\n",
            "norm    5491\n",
            "Name: label, dtype: int64\n",
            "Loss after epoch 0: 639689.75\n",
            "Loss after epoch 1: 521361.0\n",
            "Loss after epoch 2: 482243.25\n",
            "Loss after epoch 3: 446210.25\n",
            "Loss after epoch 4: 422036.75\n",
            "Loss after epoch 5: 408346.0\n",
            "Loss after epoch 6: 397455.0\n",
            "Loss after epoch 7: 391782.25\n",
            "Loss after epoch 8: 384658.0\n",
            "Loss after epoch 9: 342470.25\n",
            "Loss after epoch 10: 326429.5\n",
            "Loss after epoch 11: 325858.0\n",
            "Loss after epoch 12: 318592.5\n",
            "Loss after epoch 13: 316216.0\n",
            "Loss after epoch 14: 313739.0\n",
            "Loss after epoch 15: 313644.5\n",
            "Loss after epoch 16: 312468.0\n",
            "Loss after epoch 17: 308231.5\n",
            "Loss after epoch 18: 302789.0\n",
            "Loss after epoch 19: 306254.0\n",
            "Loss after epoch 20: 300195.5\n",
            "Loss after epoch 21: 299325.5\n",
            "Loss after epoch 22: 306739.5\n",
            "Loss after epoch 23: 323180.0\n",
            "Loss after epoch 24: 324660.0\n",
            "Loss after epoch 25: 323174.0\n",
            "Loss after epoch 26: 324283.0\n",
            "Loss after epoch 27: 316665.0\n",
            "Loss after epoch 28: 319693.0\n",
            "Loss after epoch 29: 313478.0\n",
            "anadir.jsp\n",
            "Vocabulary size: 25923\n",
            "24358\n",
            "24358\n",
            "Create Embedding matrix\n",
            "Embedding matrix: (25924, 128)\n",
            "Build Keras model\n",
            "[18212, 11712, 70, 22073, 18461, 19073, 17484, 7700, 6933] [10426, 11712, 70, 22073, 18461, 3114, 3247, 8694]\n",
            "[10426, 11712, 70, 22073, 10567, 9070, 2936, 13993, 23752, 32] [10426, 11712, 70, 22073, 18461, 2346, 18271, 70]\n",
            "[18212, 11712, 70, 22073, 18461, 19073, 8451, 0, 0] [10426, 11712, 70, 22073, 18461, 19073, 6806, 70]\n",
            "x_train shape: (149801, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0 18212\n",
            " 11712    70 22073 18461 19073 17484  7700  6933]\n",
            "x_val shape: (11806, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0 10426 11712\n",
            "    70 22073 10567  9070  2936 13993 23752    32]\n",
            "x_test shape: (61978, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0 18212\n",
            " 11712    70 22073 18461 19073  8451     0     0]\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 19, 300)           77100     \n",
            "_________________________________________________________________\n",
            "layer_normalization (LayerNo (None, 19, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 19, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,165,894\n",
            "Trainable params: 2,847,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5849 - accuracy: 0.6435\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5236 - accuracy: 0.6761\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.5113 - accuracy: 0.6842\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.5031 - accuracy: 0.6891\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.4977 - accuracy: 0.6926\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.4939 - accuracy: 0.6945\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4906 - accuracy: 0.6955\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.4868 - accuracy: 0.6976\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.4858 - accuracy: 0.6971\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.4834 - accuracy: 0.6987\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.4820 - accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4806 - accuracy: 0.7005\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4797 - accuracy: 0.7004\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.4781 - accuracy: 0.7004\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.4778 - accuracy: 0.7007\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.4770 - accuracy: 0.7011\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.4757 - accuracy: 0.7021\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4755 - accuracy: 0.7017\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.4745 - accuracy: 0.7030\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.4737 - accuracy: 0.7024\n",
            ">Saved models/model_10.h5\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 18, 300)           115500    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 18, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 18, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,204,294\n",
            "Trainable params: 2,886,022\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5158 - accuracy: 0.6955\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.4033 - accuracy: 0.7509\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.3871 - accuracy: 0.7628\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.3772 - accuracy: 0.7686\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.3701 - accuracy: 0.7720\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.3650 - accuracy: 0.7751\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.3616 - accuracy: 0.7767\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3581 - accuracy: 0.7776\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3564 - accuracy: 0.7780\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.3539 - accuracy: 0.7795\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.3514 - accuracy: 0.7817\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.3507 - accuracy: 0.7813\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.3486 - accuracy: 0.7817\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3487 - accuracy: 0.7828\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.3471 - accuracy: 0.7828\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3460 - accuracy: 0.7835\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.3458 - accuracy: 0.7834\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.3445 - accuracy: 0.7841\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3445 - accuracy: 0.7839\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3434 - accuracy: 0.7836\n",
            ">Saved models/model_20.h5\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 17, 300)           153900    \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 17, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,935,494\n",
            "Trainable params: 2,617,222\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.6281 - accuracy: 0.6233\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5320 - accuracy: 0.6689\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.5164 - accuracy: 0.6827\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.5082 - accuracy: 0.6873\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.5033 - accuracy: 0.6907\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.4987 - accuracy: 0.6929\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4956 - accuracy: 0.6939\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.4936 - accuracy: 0.6943\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.4906 - accuracy: 0.6959\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.4894 - accuracy: 0.6971\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.4888 - accuracy: 0.6977\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.4867 - accuracy: 0.6978\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.4855 - accuracy: 0.6991\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.4849 - accuracy: 0.6986\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4837 - accuracy: 0.6983\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.4830 - accuracy: 0.6995\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.4813 - accuracy: 0.6999\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4807 - accuracy: 0.7000\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.4807 - accuracy: 0.7003\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.4796 - accuracy: 0.7009\n",
            ">Saved models/model_30.h5\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 16, 300)           192300    \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 16, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_7 (Layer (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,973,894\n",
            "Trainable params: 2,655,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.5764 - accuracy: 0.6607\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.4218 - accuracy: 0.7427\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.4007 - accuracy: 0.7569\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.3900 - accuracy: 0.7631\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.3826 - accuracy: 0.7683\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3771 - accuracy: 0.7706\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.3719 - accuracy: 0.7724\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3689 - accuracy: 0.7740\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3663 - accuracy: 0.7754\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.3640 - accuracy: 0.7755\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.3619 - accuracy: 0.7771\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.3599 - accuracy: 0.7773\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3582 - accuracy: 0.7791\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3570 - accuracy: 0.7787\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3559 - accuracy: 0.7788\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.3545 - accuracy: 0.7798\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.3531 - accuracy: 0.7802\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3524 - accuracy: 0.7814\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3511 - accuracy: 0.7812\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3510 - accuracy: 0.7820\n",
            ">Saved models/model_40.h5\n",
            ">loaded models/model_10.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_20.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_30.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_40.h5\n",
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ensemble_10_input_1 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_input_2 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_input_3 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_input_4 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_embedding (Embeddin (None, 20, 128)      3318272     ensemble_10_input_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_embedding_1 (Embedd (None, 20, 128)      3318272     ensemble_20_input_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_embedding_2 (Embedd (None, 20, 128)      3318272     ensemble_30_input_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_embedding_3 (Embedd (None, 20, 128)      3318272     ensemble_40_input_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_conv1d (Conv1D)     (None, 19, 300)      77100       ensemble_10_embedding[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_conv1d_1 (Conv1D)   (None, 18, 300)      115500      ensemble_20_embedding_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_conv1d_2 (Conv1D)   (None, 17, 300)      153900      ensemble_30_embedding_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_conv1d_3 (Conv1D)   (None, 16, 300)      192300      ensemble_40_embedding_3[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_layer_normalization (None, 19, 300)      600         ensemble_10_conv1d[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_layer_normalization (None, 18, 300)      600         ensemble_20_conv1d_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_layer_normalization (None, 17, 300)      600         ensemble_30_conv1d_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_layer_normalization (None, 16, 300)      600         ensemble_40_conv1d_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_dropout (Dropout)   (None, 19, 300)      0           ensemble_10_layer_normalization[0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_dropout_2 (Dropout) (None, 18, 300)      0           ensemble_20_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_dropout_4 (Dropout) (None, 17, 300)      0           ensemble_30_layer_normalization_4\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_dropout_6 (Dropout) (None, 16, 300)      0           ensemble_40_layer_normalization_6\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_max_pooling1d (MaxP (None, 9, 300)       0           ensemble_10_dropout[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_max_pooling1d_1 (Ma (None, 9, 300)       0           ensemble_20_dropout_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_max_pooling1d_2 (Ma (None, 8, 300)       0           ensemble_30_dropout_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_max_pooling1d_3 (Ma (None, 8, 300)       0           ensemble_40_dropout_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_flatten (Flatten)   (None, 2700)         0           ensemble_10_max_pooling1d[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_flatten_1 (Flatten) (None, 2700)         0           ensemble_20_max_pooling1d_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_flatten_2 (Flatten) (None, 2400)         0           ensemble_30_max_pooling1d_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_flatten_3 (Flatten) (None, 2400)         0           ensemble_40_max_pooling1d_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_dense (Dense)       (None, 1024)         2765824     ensemble_10_flatten[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_dense_2 (Dense)     (None, 1024)         2765824     ensemble_20_flatten_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_dense_4 (Dense)     (None, 1024)         2458624     ensemble_30_flatten_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_dense_6 (Dense)     (None, 1024)         2458624     ensemble_40_flatten_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_layer_normalization (None, 1024)         2048        ensemble_10_dense[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_layer_normalization (None, 1024)         2048        ensemble_20_dense_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_layer_normalization (None, 1024)         2048        ensemble_30_dense_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_layer_normalization (None, 1024)         2048        ensemble_40_dense_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_dropout_1 (Dropout) (None, 1024)         0           ensemble_10_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_dropout_3 (Dropout) (None, 1024)         0           ensemble_20_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_dropout_5 (Dropout) (None, 1024)         0           ensemble_30_layer_normalization_5\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_dropout_7 (Dropout) (None, 1024)         0           ensemble_40_layer_normalization_7\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_10_dense_1 (Dense)     (None, 2)            2050        ensemble_10_dropout_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_20_dense_3 (Dense)     (None, 2)            2050        ensemble_20_dropout_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_30_dense_5 (Dense)     (None, 2)            2050        ensemble_30_dropout_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_40_dense_7 (Dense)     (None, 2)            2050        ensemble_40_dropout_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           ensemble_10_dense_1[0][0]        \n",
            "                                                                 ensemble_20_dense_3[0][0]        \n",
            "                                                                 ensemble_30_dense_5[0][0]        \n",
            "                                                                 ensemble_40_dense_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 10)           90          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            22          dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,279,688\n",
            "Trainable params: 112\n",
            "Non-trainable params: 24,279,576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[array([[    0,     0,     0, ...,  8451,     0,     0],\n",
            "       [    0,     0,     0, ..., 19073,  6806,    70],\n",
            "       [    0,     0,     0, ...,  8255,  6806,    70],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8255, 13988, 15669],\n",
            "       [    0,     0,     0, ..., 17227,  3247,  6516],\n",
            "       [    0,     0,     0, ..., 19073, 16556,    70]], dtype=int32), array([[    0,     0,     0, ...,  8451,     0,     0],\n",
            "       [    0,     0,     0, ..., 19073,  6806,    70],\n",
            "       [    0,     0,     0, ...,  8255,  6806,    70],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8255, 13988, 15669],\n",
            "       [    0,     0,     0, ..., 17227,  3247,  6516],\n",
            "       [    0,     0,     0, ..., 19073, 16556,    70]], dtype=int32), array([[    0,     0,     0, ...,  8451,     0,     0],\n",
            "       [    0,     0,     0, ..., 19073,  6806,    70],\n",
            "       [    0,     0,     0, ...,  8255,  6806,    70],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8255, 13988, 15669],\n",
            "       [    0,     0,     0, ..., 17227,  3247,  6516],\n",
            "       [    0,     0,     0, ..., 19073, 16556,    70]], dtype=int32), array([[    0,     0,     0, ...,  8451,     0,     0],\n",
            "       [    0,     0,     0, ..., 19073,  6806,    70],\n",
            "       [    0,     0,     0, ...,  8255,  6806,    70],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8255, 13988, 15669],\n",
            "       [    0,     0,     0, ..., 17227,  3247,  6516],\n",
            "       [    0,     0,     0, ..., 19073, 16556,    70]], dtype=int32)]\n",
            "Epoch 1/20\n",
            "485/485 [==============================] - 4s 8ms/step - loss: 0.3810 - accuracy: 0.7739\n",
            "Epoch 2/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3680 - accuracy: 0.7781\n",
            "Epoch 3/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3679 - accuracy: 0.7782\n",
            "Epoch 4/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3675 - accuracy: 0.7797\n",
            "Epoch 5/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3685 - accuracy: 0.7782\n",
            "Epoch 6/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3681 - accuracy: 0.7772\n",
            "Epoch 7/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3679 - accuracy: 0.7787\n",
            "Epoch 8/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3681 - accuracy: 0.7776\n",
            "Epoch 9/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3674 - accuracy: 0.7786\n",
            "Epoch 10/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3677 - accuracy: 0.7774\n",
            "Epoch 11/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3675 - accuracy: 0.7779\n",
            "Epoch 12/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3669 - accuracy: 0.7786\n",
            "Epoch 13/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3673 - accuracy: 0.7784\n",
            "Epoch 14/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3668 - accuracy: 0.7784\n",
            "Epoch 15/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3667 - accuracy: 0.7798\n",
            "Epoch 16/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3670 - accuracy: 0.7789\n",
            "Epoch 17/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3665 - accuracy: 0.7789\n",
            "Epoch 18/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3665 - accuracy: 0.7783\n",
            "Epoch 19/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3670 - accuracy: 0.7792\n",
            "Epoch 20/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3662 - accuracy: 0.7795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81      6315\n",
            "           1       0.85      0.64      0.73      5491\n",
            "\n",
            "    accuracy                           0.78     11806\n",
            "   macro avg       0.80      0.77      0.77     11806\n",
            "weighted avg       0.79      0.78      0.78     11806\n",
            "\n",
            "RUN:0.000000\n",
            "Accuracy: 78.019651, loss:0.360918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "                                                      URL label\n",
            "192711  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "128325  GET http://localhost:8080/tienda1/imagenes/log...  norm\n",
            "70848   POST http://localhost:8080/tienda1/miembros/ed...  anom\n",
            "72512   POST http://localhost:8080/tienda1/publico/ana...  anom\n",
            "189888  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "(149801, 2)\n",
            "anom    80121\n",
            "norm    69680\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "77509   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "144478  GET http://localhost:8080/tienda1/publico/regi...  norm\n",
            "78822   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "187425  POST http://localhost:8080/tienda1/publico/ana...  norm\n",
            "22156   GET http://localhost:8080/tienda1/publico/anad...  anom\n",
            "(61978, 2)\n",
            "anom    33149\n",
            "norm    28829\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "171041  GET http://localhost:8080/tienda1/imagenes/3.gif?  norm\n",
            "126029  GET http://localhost:8080/tienda1/imagenes/3.gif?  norm\n",
            "135194  GET http://localhost:8080/tienda1/miembros/edi...  norm\n",
            "74376   POST http://localhost:8080/tienda1/miembros/ed...  anom\n",
            "66825   POST http://localhost:8080/tienda1/publico/pag...  anom\n",
            "(11806, 2)\n",
            "anom    6315\n",
            "norm    5491\n",
            "Name: label, dtype: int64\n",
            "Loss after epoch 0: 637220.4375\n",
            "Loss after epoch 1: 521271.6875\n",
            "Loss after epoch 2: 476270.625\n",
            "Loss after epoch 3: 454597.25\n",
            "Loss after epoch 4: 419676.75\n",
            "Loss after epoch 5: 406865.25\n",
            "Loss after epoch 6: 407135.0\n",
            "Loss after epoch 7: 390299.0\n",
            "Loss after epoch 8: 383720.25\n",
            "Loss after epoch 9: 338375.75\n",
            "Loss after epoch 10: 326530.0\n",
            "Loss after epoch 11: 323317.0\n",
            "Loss after epoch 12: 321531.0\n",
            "Loss after epoch 13: 320737.0\n",
            "Loss after epoch 14: 313130.5\n",
            "Loss after epoch 15: 313733.0\n",
            "Loss after epoch 16: 308024.0\n",
            "Loss after epoch 17: 304968.5\n",
            "Loss after epoch 18: 306105.5\n",
            "Loss after epoch 19: 302540.5\n",
            "Loss after epoch 20: 304063.5\n",
            "Loss after epoch 21: 302973.5\n",
            "Loss after epoch 22: 308024.0\n",
            "Loss after epoch 23: 327052.0\n",
            "Loss after epoch 24: 325667.0\n",
            "Loss after epoch 25: 322878.0\n",
            "Loss after epoch 26: 319759.0\n",
            "Loss after epoch 27: 318000.0\n",
            "Loss after epoch 28: 314147.0\n",
            "Loss after epoch 29: 313888.0\n",
            "anadir.jsp\n",
            "Vocabulary size: 25923\n",
            "24394\n",
            "24394\n",
            "Create Embedding matrix\n",
            "Embedding matrix: (25924, 128)\n",
            "Build Keras model\n",
            "[18281, 11782, 73, 22099, 15381, 8287, 6838, 73] [10464, 11782, 73, 22099, 12030, 14093]\n",
            "[10464, 11782, 73, 22099, 12030, 89] [10464, 11782, 73, 22099, 12030, 89]\n",
            "[18281, 11782, 73, 22099, 18529, 19129, 6838, 73] [10464, 11782, 73, 22099, 18529, 19129, 3248, 19123]\n",
            "x_train shape: (149801, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 18281 11782    73 22099 15381  8287  6838    73]\n",
            "x_val shape: (11806, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0 10464 11782    73 22099 12030    89]\n",
            "x_test shape: (61978, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 18281 11782    73 22099 18529 19129  6838    73]\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 19, 300)           77100     \n",
            "_________________________________________________________________\n",
            "layer_normalization_8 (Layer (None, 19, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 19, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,165,894\n",
            "Trainable params: 2,847,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5954 - accuracy: 0.6405\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.5244 - accuracy: 0.6710\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.5101 - accuracy: 0.6858\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.5032 - accuracy: 0.6905\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.4979 - accuracy: 0.6933\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.4940 - accuracy: 0.6957\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.4913 - accuracy: 0.6964\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.4885 - accuracy: 0.6982\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.4867 - accuracy: 0.6991\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.4855 - accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.4837 - accuracy: 0.7003\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4817 - accuracy: 0.7008\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4809 - accuracy: 0.7020\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.4794 - accuracy: 0.7016\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.4795 - accuracy: 0.7024\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.4777 - accuracy: 0.7027\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.4773 - accuracy: 0.7033\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.4766 - accuracy: 0.7028\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.4759 - accuracy: 0.7039\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.4751 - accuracy: 0.7034\n",
            ">Saved models/model_11.h5\n",
            "Model: \"functional_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 18, 300)           115500    \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 18, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 18, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_11 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,204,294\n",
            "Trainable params: 2,886,022\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5235 - accuracy: 0.6964\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.4011 - accuracy: 0.7562\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.3852 - accuracy: 0.7662\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.3774 - accuracy: 0.7703\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.3722 - accuracy: 0.7734\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.3675 - accuracy: 0.7753\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.3633 - accuracy: 0.7769\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.3599 - accuracy: 0.7785\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.3572 - accuracy: 0.7800\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.3556 - accuracy: 0.7807\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.3536 - accuracy: 0.7807\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.3516 - accuracy: 0.7821\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3514 - accuracy: 0.7823\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.3494 - accuracy: 0.7836\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.3484 - accuracy: 0.7830\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3474 - accuracy: 0.7844\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.3469 - accuracy: 0.7837\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.3455 - accuracy: 0.7848\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.3441 - accuracy: 0.7855\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.3441 - accuracy: 0.7846\n",
            ">Saved models/model_21.h5\n",
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 17, 300)           153900    \n",
            "_________________________________________________________________\n",
            "layer_normalization_12 (Laye (None, 17, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,935,494\n",
            "Trainable params: 2,617,222\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.6320 - accuracy: 0.6250\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5364 - accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.5199 - accuracy: 0.6795\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.5102 - accuracy: 0.6871\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.5047 - accuracy: 0.6899\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.5004 - accuracy: 0.6925\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4976 - accuracy: 0.6943\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.4948 - accuracy: 0.6948\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.4923 - accuracy: 0.6972\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.4910 - accuracy: 0.6972\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.4889 - accuracy: 0.6988\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4874 - accuracy: 0.6989\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4866 - accuracy: 0.6987\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.4853 - accuracy: 0.7002\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4843 - accuracy: 0.6999\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.4837 - accuracy: 0.7010\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.4824 - accuracy: 0.7011\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4821 - accuracy: 0.7004\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.4816 - accuracy: 0.7011\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.4805 - accuracy: 0.7017\n",
            ">Saved models/model_31.h5\n",
            "Model: \"functional_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 16, 300)           192300    \n",
            "_________________________________________________________________\n",
            "layer_normalization_14 (Laye (None, 16, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 16, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_15 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,973,894\n",
            "Trainable params: 2,655,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.5498 - accuracy: 0.6732\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.4177 - accuracy: 0.7474\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.4010 - accuracy: 0.7589\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.3884 - accuracy: 0.7650\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.3814 - accuracy: 0.7681\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3745 - accuracy: 0.7715\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.3722 - accuracy: 0.7727\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3682 - accuracy: 0.7749\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3660 - accuracy: 0.7753\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.3623 - accuracy: 0.7769\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.3613 - accuracy: 0.7783\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.3595 - accuracy: 0.7779\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3575 - accuracy: 0.7792\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3570 - accuracy: 0.7797\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3547 - accuracy: 0.7809\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.3535 - accuracy: 0.7815\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.3528 - accuracy: 0.7813\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3524 - accuracy: 0.7815\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3514 - accuracy: 0.7821\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3503 - accuracy: 0.7824\n",
            ">Saved models/model_41.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_11.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_21.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_31.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_41.h5\n",
            "Model: \"functional_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ensemble_11_input_5 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_input_6 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_input_7 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_input_8 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_embedding_4 (Embedd (None, 20, 128)      3318272     ensemble_11_input_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_embedding_5 (Embedd (None, 20, 128)      3318272     ensemble_21_input_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_embedding_6 (Embedd (None, 20, 128)      3318272     ensemble_31_input_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_embedding_7 (Embedd (None, 20, 128)      3318272     ensemble_41_input_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_conv1d_4 (Conv1D)   (None, 19, 300)      77100       ensemble_11_embedding_4[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_conv1d_5 (Conv1D)   (None, 18, 300)      115500      ensemble_21_embedding_5[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_conv1d_6 (Conv1D)   (None, 17, 300)      153900      ensemble_31_embedding_6[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_conv1d_7 (Conv1D)   (None, 16, 300)      192300      ensemble_41_embedding_7[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_layer_normalization (None, 19, 300)      600         ensemble_11_conv1d_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_layer_normalization (None, 18, 300)      600         ensemble_21_conv1d_5[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_layer_normalization (None, 17, 300)      600         ensemble_31_conv1d_6[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_layer_normalization (None, 16, 300)      600         ensemble_41_conv1d_7[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_dropout_8 (Dropout) (None, 19, 300)      0           ensemble_11_layer_normalization_8\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_dropout_10 (Dropout (None, 18, 300)      0           ensemble_21_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_dropout_12 (Dropout (None, 17, 300)      0           ensemble_31_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_dropout_14 (Dropout (None, 16, 300)      0           ensemble_41_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_max_pooling1d_4 (Ma (None, 9, 300)       0           ensemble_11_dropout_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_max_pooling1d_5 (Ma (None, 9, 300)       0           ensemble_21_dropout_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_max_pooling1d_6 (Ma (None, 8, 300)       0           ensemble_31_dropout_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_max_pooling1d_7 (Ma (None, 8, 300)       0           ensemble_41_dropout_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_flatten_4 (Flatten) (None, 2700)         0           ensemble_11_max_pooling1d_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_flatten_5 (Flatten) (None, 2700)         0           ensemble_21_max_pooling1d_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_flatten_6 (Flatten) (None, 2400)         0           ensemble_31_max_pooling1d_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_flatten_7 (Flatten) (None, 2400)         0           ensemble_41_max_pooling1d_7[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_dense_10 (Dense)    (None, 1024)         2765824     ensemble_11_flatten_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_dense_12 (Dense)    (None, 1024)         2765824     ensemble_21_flatten_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_dense_14 (Dense)    (None, 1024)         2458624     ensemble_31_flatten_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_dense_16 (Dense)    (None, 1024)         2458624     ensemble_41_flatten_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_layer_normalization (None, 1024)         2048        ensemble_11_dense_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_layer_normalization (None, 1024)         2048        ensemble_21_dense_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_layer_normalization (None, 1024)         2048        ensemble_31_dense_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_layer_normalization (None, 1024)         2048        ensemble_41_dense_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_dropout_9 (Dropout) (None, 1024)         0           ensemble_11_layer_normalization_9\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_dropout_11 (Dropout (None, 1024)         0           ensemble_21_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_dropout_13 (Dropout (None, 1024)         0           ensemble_31_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_dropout_15 (Dropout (None, 1024)         0           ensemble_41_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_11_dense_11 (Dense)    (None, 2)            2050        ensemble_11_dropout_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_21_dense_13 (Dense)    (None, 2)            2050        ensemble_21_dropout_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_31_dense_15 (Dense)    (None, 2)            2050        ensemble_31_dropout_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_41_dense_17 (Dense)    (None, 2)            2050        ensemble_41_dropout_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8)            0           ensemble_11_dense_11[0][0]       \n",
            "                                                                 ensemble_21_dense_13[0][0]       \n",
            "                                                                 ensemble_31_dense_15[0][0]       \n",
            "                                                                 ensemble_41_dense_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 10)           90          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 2)            22          dense_18[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,279,688\n",
            "Trainable params: 112\n",
            "Non-trainable params: 24,279,576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[array([[    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       [    0,     0,     0, ..., 19129,  3248, 19123],\n",
            "       [    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16553, 18686, 14597],\n",
            "       [    0,     0,     0, ..., 22099, 15381,  9847],\n",
            "       [    0,     0,     0, ..., 22099, 18529,  5385]], dtype=int32), array([[    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       [    0,     0,     0, ..., 19129,  3248, 19123],\n",
            "       [    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16553, 18686, 14597],\n",
            "       [    0,     0,     0, ..., 22099, 15381,  9847],\n",
            "       [    0,     0,     0, ..., 22099, 18529,  5385]], dtype=int32), array([[    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       [    0,     0,     0, ..., 19129,  3248, 19123],\n",
            "       [    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16553, 18686, 14597],\n",
            "       [    0,     0,     0, ..., 22099, 15381,  9847],\n",
            "       [    0,     0,     0, ..., 22099, 18529,  5385]], dtype=int32), array([[    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       [    0,     0,     0, ..., 19129,  3248, 19123],\n",
            "       [    0,     0,     0, ..., 19129,  6838,    73],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16553, 18686, 14597],\n",
            "       [    0,     0,     0, ..., 22099, 15381,  9847],\n",
            "       [    0,     0,     0, ..., 22099, 18529,  5385]], dtype=int32)]\n",
            "Epoch 1/20\n",
            "485/485 [==============================] - 4s 8ms/step - loss: 0.3810 - accuracy: 0.7731\n",
            "Epoch 2/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3698 - accuracy: 0.7762\n",
            "Epoch 3/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3696 - accuracy: 0.7745\n",
            "Epoch 4/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3681 - accuracy: 0.7763\n",
            "Epoch 5/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3680 - accuracy: 0.7752\n",
            "Epoch 6/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3686 - accuracy: 0.7753\n",
            "Epoch 7/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3677 - accuracy: 0.7757\n",
            "Epoch 8/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3675 - accuracy: 0.7752\n",
            "Epoch 9/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3676 - accuracy: 0.7762\n",
            "Epoch 10/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3673 - accuracy: 0.7760\n",
            "Epoch 11/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3675 - accuracy: 0.7756\n",
            "Epoch 12/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3673 - accuracy: 0.7763\n",
            "Epoch 13/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3667 - accuracy: 0.7758\n",
            "Epoch 14/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3663 - accuracy: 0.7769\n",
            "Epoch 15/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3664 - accuracy: 0.7765\n",
            "Epoch 16/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3663 - accuracy: 0.7786\n",
            "Epoch 17/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3666 - accuracy: 0.7759\n",
            "Epoch 18/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3665 - accuracy: 0.7771\n",
            "Epoch 19/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3667 - accuracy: 0.7763\n",
            "Epoch 20/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3663 - accuracy: 0.7773\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.83      6315\n",
            "           1       0.92      0.59      0.72      5491\n",
            "\n",
            "    accuracy                           0.78     11806\n",
            "   macro avg       0.82      0.77      0.77     11806\n",
            "weighted avg       0.82      0.78      0.77     11806\n",
            "\n",
            "RUN:1.000000\n",
            "Accuracy: 78.400813, loss:0.361282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "                                                      URL label\n",
            "25548   GET http://localhost:8080/tienda1/publico/anad...  anom\n",
            "114225  POST http://localhost:8080/tienda1/publico/pag...  anom\n",
            "67944   POST http://localhost:8080/tienda1/publico/ana...  anom\n",
            "201337  POST http://localhost:8080/tienda1/publico/pag...  norm\n",
            "117206  POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "(149801, 2)\n",
            "anom    80121\n",
            "norm    69680\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "134     GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "213240  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "36461   GET http://localhost:8080/tienda1/publico/paga...  anom\n",
            "60206   GET http://localhost:8080/tienda1/publico/aute...  anom\n",
            "67534   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "(61978, 2)\n",
            "anom    33149\n",
            "norm    28829\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "28374   GET http://localhost:8080/tienda1/publico/anad...  anom\n",
            "10578   GET http://localhost:8080/tienda1/publico/regi...  anom\n",
            "183135  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "173046  GET http://localhost:8080/tienda1/publico/paga...  norm\n",
            "153692  GET http://localhost:8080/tienda1/publico/aute...  norm\n",
            "(11806, 2)\n",
            "anom    6315\n",
            "norm    5491\n",
            "Name: label, dtype: int64\n",
            "Loss after epoch 0: 639586.75\n",
            "Loss after epoch 1: 515350.25\n",
            "Loss after epoch 2: 477947.0\n",
            "Loss after epoch 3: 451576.75\n",
            "Loss after epoch 4: 426584.25\n",
            "Loss after epoch 5: 413781.75\n",
            "Loss after epoch 6: 400133.5\n",
            "Loss after epoch 7: 390448.0\n",
            "Loss after epoch 8: 383326.5\n",
            "Loss after epoch 9: 342322.75\n",
            "Loss after epoch 10: 325764.5\n",
            "Loss after epoch 11: 326172.5\n",
            "Loss after epoch 12: 318967.0\n",
            "Loss after epoch 13: 319109.0\n",
            "Loss after epoch 14: 318540.0\n",
            "Loss after epoch 15: 312860.0\n",
            "Loss after epoch 16: 308498.5\n",
            "Loss after epoch 17: 309616.5\n",
            "Loss after epoch 18: 305968.0\n",
            "Loss after epoch 19: 303864.0\n",
            "Loss after epoch 20: 300978.5\n",
            "Loss after epoch 21: 298088.5\n",
            "Loss after epoch 22: 308139.5\n",
            "Loss after epoch 23: 331870.0\n",
            "Loss after epoch 24: 323967.0\n",
            "Loss after epoch 25: 321833.0\n",
            "Loss after epoch 26: 317991.0\n",
            "Loss after epoch 27: 319512.0\n",
            "Loss after epoch 28: 315787.0\n",
            "Loss after epoch 29: 313447.0\n",
            "anadir.jsp\n",
            "Vocabulary size: 25923\n",
            "24371\n",
            "24371\n",
            "Create Embedding matrix\n",
            "Embedding matrix: (25924, 128)\n",
            "Build Keras model\n",
            "[10463, 11768, 66, 22073, 18504, 2369, 5212, 66] [18264, 11768, 66, 22073, 18504, 17268, 3254, 6553]\n",
            "[10463, 11768, 66, 22073, 18504, 2369, 16521, 18666, 14571] [10463, 11768, 66, 22073, 18504, 19102, 17528, 923, 66]\n",
            "[10463, 11768, 66, 22073, 15356, 8287, 7791, 5025, 1875, 66] [18264, 11768, 66, 22073, 15356, 8287, 15553, 19101]\n",
            "x_train shape: (149801, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 10463 11768    66 22073 18504  2369  5212    66]\n",
            "x_val shape: (11806, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0 10463\n",
            " 11768    66 22073 18504  2369 16521 18666 14571]\n",
            "x_test shape: (61978, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0 10463 11768\n",
            "    66 22073 15356  8287  7791  5025  1875    66]\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"functional_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 19, 300)           77100     \n",
            "_________________________________________________________________\n",
            "layer_normalization_16 (Laye (None, 19, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 19, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_17 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,165,894\n",
            "Trainable params: 2,847,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.6137 - accuracy: 0.6360\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.5231 - accuracy: 0.6761\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.5093 - accuracy: 0.6876\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.5022 - accuracy: 0.6912\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.4969 - accuracy: 0.6944\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.4933 - accuracy: 0.6960\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.4901 - accuracy: 0.6964\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.4877 - accuracy: 0.6982\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.4856 - accuracy: 0.6987\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.4843 - accuracy: 0.6989\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.4821 - accuracy: 0.7010\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4808 - accuracy: 0.7013\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4790 - accuracy: 0.7017\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.4783 - accuracy: 0.7014\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.4775 - accuracy: 0.7027\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.4768 - accuracy: 0.7022\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.4760 - accuracy: 0.7025\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.4753 - accuracy: 0.7024\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.4752 - accuracy: 0.7032\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.4743 - accuracy: 0.7031\n",
            ">Saved models/model_12.h5\n",
            "Model: \"functional_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 18, 300)           115500    \n",
            "_________________________________________________________________\n",
            "layer_normalization_18 (Laye (None, 18, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 18, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_19 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,204,294\n",
            "Trainable params: 2,886,022\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5432 - accuracy: 0.6845\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.4037 - accuracy: 0.7537\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.3854 - accuracy: 0.7652\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.3762 - accuracy: 0.7705\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.3697 - accuracy: 0.7731\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.3651 - accuracy: 0.7759\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.3618 - accuracy: 0.7772\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.3586 - accuracy: 0.7791\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.3565 - accuracy: 0.7793\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.3537 - accuracy: 0.7804\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.3529 - accuracy: 0.7805\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.3509 - accuracy: 0.7807\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.3488 - accuracy: 0.7817\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.3488 - accuracy: 0.7825\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.3469 - accuracy: 0.7837\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3472 - accuracy: 0.7833\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.3455 - accuracy: 0.7838\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.3448 - accuracy: 0.7843\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.3441 - accuracy: 0.7850\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.3430 - accuracy: 0.7853\n",
            ">Saved models/model_22.h5\n",
            "Model: \"functional_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 17, 300)           153900    \n",
            "_________________________________________________________________\n",
            "layer_normalization_20 (Laye (None, 17, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_21 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,935,494\n",
            "Trainable params: 2,617,222\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.6243 - accuracy: 0.6252\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5358 - accuracy: 0.6680\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.5171 - accuracy: 0.6809\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.5086 - accuracy: 0.6874\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.5033 - accuracy: 0.6910\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.4994 - accuracy: 0.6922\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4964 - accuracy: 0.6942\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.4933 - accuracy: 0.6959\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.4919 - accuracy: 0.6963\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.4904 - accuracy: 0.6964\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.4881 - accuracy: 0.6975\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.4873 - accuracy: 0.6986\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.4860 - accuracy: 0.6990\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.4848 - accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4841 - accuracy: 0.6988\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.4824 - accuracy: 0.7004\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.4815 - accuracy: 0.7013\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4809 - accuracy: 0.7010\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.4811 - accuracy: 0.7008\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.4800 - accuracy: 0.7017\n",
            ">Saved models/model_32.h5\n",
            "Model: \"functional_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_11 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 16, 300)           192300    \n",
            "_________________________________________________________________\n",
            "layer_normalization_22 (Laye (None, 16, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 16, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_23 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,973,894\n",
            "Trainable params: 2,655,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5772 - accuracy: 0.6555\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.4166 - accuracy: 0.7480\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.3969 - accuracy: 0.7604\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.3867 - accuracy: 0.7665\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.3808 - accuracy: 0.7690\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3747 - accuracy: 0.7717\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.3711 - accuracy: 0.7729\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3673 - accuracy: 0.7748\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3651 - accuracy: 0.7756\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.3628 - accuracy: 0.7766\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.3601 - accuracy: 0.7777\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.3590 - accuracy: 0.7782\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3568 - accuracy: 0.7791\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3549 - accuracy: 0.7799\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3547 - accuracy: 0.7800\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.3529 - accuracy: 0.7812\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.3533 - accuracy: 0.7809\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3509 - accuracy: 0.7816\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3507 - accuracy: 0.7818\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3495 - accuracy: 0.7822\n",
            ">Saved models/model_42.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_12.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_22.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_32.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_42.h5\n",
            "Model: \"functional_29\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ensemble_12_input_9 (InputLayer [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_input_10 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_input_11 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_input_12 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_embedding_8 (Embedd (None, 20, 128)      3318272     ensemble_12_input_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_embedding_9 (Embedd (None, 20, 128)      3318272     ensemble_22_input_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_embedding_10 (Embed (None, 20, 128)      3318272     ensemble_32_input_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_embedding_11 (Embed (None, 20, 128)      3318272     ensemble_42_input_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_conv1d_8 (Conv1D)   (None, 19, 300)      77100       ensemble_12_embedding_8[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_conv1d_9 (Conv1D)   (None, 18, 300)      115500      ensemble_22_embedding_9[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_conv1d_10 (Conv1D)  (None, 17, 300)      153900      ensemble_32_embedding_10[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_conv1d_11 (Conv1D)  (None, 16, 300)      192300      ensemble_42_embedding_11[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_layer_normalization (None, 19, 300)      600         ensemble_12_conv1d_8[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_layer_normalization (None, 18, 300)      600         ensemble_22_conv1d_9[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_layer_normalization (None, 17, 300)      600         ensemble_32_conv1d_10[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_layer_normalization (None, 16, 300)      600         ensemble_42_conv1d_11[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_dropout_16 (Dropout (None, 19, 300)      0           ensemble_12_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_dropout_18 (Dropout (None, 18, 300)      0           ensemble_22_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_dropout_20 (Dropout (None, 17, 300)      0           ensemble_32_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_dropout_22 (Dropout (None, 16, 300)      0           ensemble_42_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_max_pooling1d_8 (Ma (None, 9, 300)       0           ensemble_12_dropout_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_max_pooling1d_9 (Ma (None, 9, 300)       0           ensemble_22_dropout_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_max_pooling1d_10 (M (None, 8, 300)       0           ensemble_32_dropout_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_max_pooling1d_11 (M (None, 8, 300)       0           ensemble_42_dropout_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_flatten_8 (Flatten) (None, 2700)         0           ensemble_12_max_pooling1d_8[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_flatten_9 (Flatten) (None, 2700)         0           ensemble_22_max_pooling1d_9[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_flatten_10 (Flatten (None, 2400)         0           ensemble_32_max_pooling1d_10[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_flatten_11 (Flatten (None, 2400)         0           ensemble_42_max_pooling1d_11[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_dense_20 (Dense)    (None, 1024)         2765824     ensemble_12_flatten_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_dense_22 (Dense)    (None, 1024)         2765824     ensemble_22_flatten_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_dense_24 (Dense)    (None, 1024)         2458624     ensemble_32_flatten_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_dense_26 (Dense)    (None, 1024)         2458624     ensemble_42_flatten_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_layer_normalization (None, 1024)         2048        ensemble_12_dense_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_layer_normalization (None, 1024)         2048        ensemble_22_dense_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_layer_normalization (None, 1024)         2048        ensemble_32_dense_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_layer_normalization (None, 1024)         2048        ensemble_42_dense_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_dropout_17 (Dropout (None, 1024)         0           ensemble_12_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_dropout_19 (Dropout (None, 1024)         0           ensemble_22_layer_normalization_1\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_dropout_21 (Dropout (None, 1024)         0           ensemble_32_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_dropout_23 (Dropout (None, 1024)         0           ensemble_42_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_12_dense_21 (Dense)    (None, 2)            2050        ensemble_12_dropout_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_22_dense_23 (Dense)    (None, 2)            2050        ensemble_22_dropout_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_32_dense_25 (Dense)    (None, 2)            2050        ensemble_32_dropout_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_42_dense_27 (Dense)    (None, 2)            2050        ensemble_42_dropout_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8)            0           ensemble_12_dense_21[0][0]       \n",
            "                                                                 ensemble_22_dense_23[0][0]       \n",
            "                                                                 ensemble_32_dense_25[0][0]       \n",
            "                                                                 ensemble_42_dense_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 10)           90          concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 2)            22          dense_28[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,279,688\n",
            "Trainable params: 112\n",
            "Non-trainable params: 24,279,576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[array([[    0,     0,     0, ...,  5025,  1875,    66],\n",
            "       [    0,     0,     0, ...,  8287, 15553, 19101],\n",
            "       [    0,     0,     0, ...,  6615, 21692,    66],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16048, 11885, 19347],\n",
            "       [    0,     0,     0, ..., 17528, 15839, 21921],\n",
            "       [    0,     0,     0, ...,  7791, 14384,    66]], dtype=int32), array([[    0,     0,     0, ...,  5025,  1875,    66],\n",
            "       [    0,     0,     0, ...,  8287, 15553, 19101],\n",
            "       [    0,     0,     0, ...,  6615, 21692,    66],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16048, 11885, 19347],\n",
            "       [    0,     0,     0, ..., 17528, 15839, 21921],\n",
            "       [    0,     0,     0, ...,  7791, 14384,    66]], dtype=int32), array([[    0,     0,     0, ...,  5025,  1875,    66],\n",
            "       [    0,     0,     0, ...,  8287, 15553, 19101],\n",
            "       [    0,     0,     0, ...,  6615, 21692,    66],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16048, 11885, 19347],\n",
            "       [    0,     0,     0, ..., 17528, 15839, 21921],\n",
            "       [    0,     0,     0, ...,  7791, 14384,    66]], dtype=int32), array([[    0,     0,     0, ...,  5025,  1875,    66],\n",
            "       [    0,     0,     0, ...,  8287, 15553, 19101],\n",
            "       [    0,     0,     0, ...,  6615, 21692,    66],\n",
            "       ...,\n",
            "       [    0,     0,     0, ..., 16048, 11885, 19347],\n",
            "       [    0,     0,     0, ..., 17528, 15839, 21921],\n",
            "       [    0,     0,     0, ...,  7791, 14384,    66]], dtype=int32)]\n",
            "Epoch 1/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3756 - accuracy: 0.7781\n",
            "Epoch 2/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3693 - accuracy: 0.7780\n",
            "Epoch 3/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3693 - accuracy: 0.7792\n",
            "Epoch 4/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3691 - accuracy: 0.7783\n",
            "Epoch 5/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3687 - accuracy: 0.7779\n",
            "Epoch 6/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3684 - accuracy: 0.7799\n",
            "Epoch 7/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3682 - accuracy: 0.7781\n",
            "Epoch 8/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3677 - accuracy: 0.7791\n",
            "Epoch 9/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3681 - accuracy: 0.7792\n",
            "Epoch 10/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3676 - accuracy: 0.7794\n",
            "Epoch 11/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3676 - accuracy: 0.7795\n",
            "Epoch 12/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3674 - accuracy: 0.7795\n",
            "Epoch 13/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3677 - accuracy: 0.7794\n",
            "Epoch 14/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3675 - accuracy: 0.7792\n",
            "Epoch 15/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3674 - accuracy: 0.7791\n",
            "Epoch 16/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3670 - accuracy: 0.7789\n",
            "Epoch 17/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3675 - accuracy: 0.7793\n",
            "Epoch 18/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3665 - accuracy: 0.7792\n",
            "Epoch 19/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3666 - accuracy: 0.7804\n",
            "Epoch 20/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3670 - accuracy: 0.7792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82      6315\n",
            "           1       0.92      0.57      0.70      5491\n",
            "\n",
            "    accuracy                           0.78     11806\n",
            "   macro avg       0.82      0.76      0.76     11806\n",
            "weighted avg       0.81      0.78      0.77     11806\n",
            "\n",
            "RUN:2.000000\n",
            "Accuracy: 77.672370, loss:0.367382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "                                                      URL label\n",
            "68941   POST http://localhost:8080/tienda1/publico/aut...  anom\n",
            "33912   GET http://localhost:8080/tienda1/publico/regi...  anom\n",
            "222062  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "68585   POST http://localhost:8080/tienda1/miembros/ed...  anom\n",
            "81031   POST http://localhost:8080/tienda1/publico/pag...  anom\n",
            "(149801, 2)\n",
            "anom    80121\n",
            "norm    69680\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "171749  GET http://localhost:8080/tienda1/publico/regi...  norm\n",
            "2903    GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "130799  GET http://localhost:8080/tienda1/miembros/fot...  norm\n",
            "64766   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "160550  GET http://localhost:8080/tienda1/miembros/edi...  norm\n",
            "(61978, 2)\n",
            "anom    33149\n",
            "norm    28829\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "9841    GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "192103  POST http://localhost:8080/tienda1/publico/reg...  norm\n",
            "63178   POST http://localhost:8080/tienda1/publico/ana...  anom\n",
            "73607   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "173158  GET http://localhost:8080/tienda1/publico/anad...  norm\n",
            "(11806, 2)\n",
            "anom    6315\n",
            "norm    5491\n",
            "Name: label, dtype: int64\n",
            "Loss after epoch 0: 637388.5625\n",
            "Loss after epoch 1: 515032.3125\n",
            "Loss after epoch 2: 476357.125\n",
            "Loss after epoch 3: 449768.5\n",
            "Loss after epoch 4: 424928.5\n",
            "Loss after epoch 5: 409895.5\n",
            "Loss after epoch 6: 401384.0\n",
            "Loss after epoch 7: 395681.25\n",
            "Loss after epoch 8: 384301.0\n",
            "Loss after epoch 9: 341844.75\n",
            "Loss after epoch 10: 325585.0\n",
            "Loss after epoch 11: 322219.0\n",
            "Loss after epoch 12: 323544.5\n",
            "Loss after epoch 13: 316800.0\n",
            "Loss after epoch 14: 313558.5\n",
            "Loss after epoch 15: 310117.5\n",
            "Loss after epoch 16: 308555.5\n",
            "Loss after epoch 17: 310187.5\n",
            "Loss after epoch 18: 306957.0\n",
            "Loss after epoch 19: 302924.5\n",
            "Loss after epoch 20: 304621.5\n",
            "Loss after epoch 21: 299316.0\n",
            "Loss after epoch 22: 306626.0\n",
            "Loss after epoch 23: 326450.0\n",
            "Loss after epoch 24: 327926.0\n",
            "Loss after epoch 25: 320217.0\n",
            "Loss after epoch 26: 319956.0\n",
            "Loss after epoch 27: 317078.0\n",
            "Loss after epoch 28: 312959.0\n",
            "Loss after epoch 29: 317105.0\n",
            "anadir.jsp\n",
            "Vocabulary size: 25923\n",
            "24436\n",
            "24436\n",
            "Create Embedding matrix\n",
            "Embedding matrix: (25924, 128)\n",
            "Build Keras model\n",
            "[18299, 11796, 70, 22137, 18543, 3117, 19196, 16985] [10485, 11796, 70, 22137, 18543, 19143, 2558, 18770, 3341, 17612]\n",
            "[10485, 11796, 70, 22137, 15403, 8305, 6848, 70] [18299, 11796, 70, 22137, 18543, 19143, 16569, 6928, 3371]\n",
            "[10485, 11796, 70, 22137, 18543, 19143, 16569, 24073, 16082] [10485, 11796, 70, 22137, 15403, 8305, 17577, 1685]\n",
            "x_train shape: (149801, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 18299 11796    70 22137 18543  3117 19196 16985]\n",
            "x_val shape: (11806, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 10485 11796    70 22137 15403  8305  6848    70]\n",
            "x_test shape: (61978, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0 10485\n",
            " 11796    70 22137 18543 19143 16569 24073 16082]\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"functional_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 19, 300)           77100     \n",
            "_________________________________________________________________\n",
            "layer_normalization_24 (Laye (None, 19, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 19, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_25 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,165,894\n",
            "Trainable params: 2,847,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.6149 - accuracy: 0.6328\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5255 - accuracy: 0.6740\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.5122 - accuracy: 0.6852\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.5039 - accuracy: 0.6905\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.4983 - accuracy: 0.6942\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.4937 - accuracy: 0.6960\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.4904 - accuracy: 0.6966\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.4879 - accuracy: 0.6985\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.4858 - accuracy: 0.6990\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.4840 - accuracy: 0.6998\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.4826 - accuracy: 0.7005\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4810 - accuracy: 0.7010\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4794 - accuracy: 0.7021\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.4791 - accuracy: 0.7014\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4778 - accuracy: 0.7025\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.4765 - accuracy: 0.7029\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.4759 - accuracy: 0.7037\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.4758 - accuracy: 0.7033\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.4750 - accuracy: 0.7036\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.4740 - accuracy: 0.7031\n",
            ">Saved models/model_13.h5\n",
            "Model: \"functional_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_13 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 18, 300)           115500    \n",
            "_________________________________________________________________\n",
            "layer_normalization_26 (Laye (None, 18, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 18, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_27 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,204,294\n",
            "Trainable params: 2,886,022\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5089 - accuracy: 0.7016\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.3999 - accuracy: 0.7550\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.3824 - accuracy: 0.7665\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.3737 - accuracy: 0.7707\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.3673 - accuracy: 0.7735\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3629 - accuracy: 0.7765\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.3606 - accuracy: 0.7770\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3568 - accuracy: 0.7786\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3545 - accuracy: 0.7797\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.3533 - accuracy: 0.7812\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.3504 - accuracy: 0.7810\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.3498 - accuracy: 0.7817\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.3479 - accuracy: 0.7828\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.3466 - accuracy: 0.7831\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3455 - accuracy: 0.7838\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3456 - accuracy: 0.7838\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.3436 - accuracy: 0.7841\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3436 - accuracy: 0.7839\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3431 - accuracy: 0.7843\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.3420 - accuracy: 0.7858\n",
            ">Saved models/model_23.h5\n",
            "Model: \"functional_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_14 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 17, 300)           153900    \n",
            "_________________________________________________________________\n",
            "layer_normalization_28 (Laye (None, 17, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_29 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,935,494\n",
            "Trainable params: 2,617,222\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.6162 - accuracy: 0.6263\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5316 - accuracy: 0.6692\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.5164 - accuracy: 0.6837\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.5085 - accuracy: 0.6900\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.5030 - accuracy: 0.6919\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.4985 - accuracy: 0.6937\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4950 - accuracy: 0.6961\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.4926 - accuracy: 0.6964\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.4908 - accuracy: 0.6972\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.4886 - accuracy: 0.6982\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.4874 - accuracy: 0.6987\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.4856 - accuracy: 0.6993\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.4847 - accuracy: 0.6996\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.4836 - accuracy: 0.7004\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4826 - accuracy: 0.7005\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.4824 - accuracy: 0.7017\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.4814 - accuracy: 0.7011\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4799 - accuracy: 0.7018\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.4796 - accuracy: 0.7020\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.4793 - accuracy: 0.7014\n",
            ">Saved models/model_33.h5\n",
            "Model: \"functional_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_15 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 16, 300)           192300    \n",
            "_________________________________________________________________\n",
            "layer_normalization_30 (Laye (None, 16, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 16, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_31 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,973,894\n",
            "Trainable params: 2,655,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.5541 - accuracy: 0.6677\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.4132 - accuracy: 0.7488\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.3956 - accuracy: 0.7612\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.3847 - accuracy: 0.7666\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.3785 - accuracy: 0.7706\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3743 - accuracy: 0.7719\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.3701 - accuracy: 0.7746\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3675 - accuracy: 0.7756\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.3638 - accuracy: 0.7769\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.3614 - accuracy: 0.7776\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.3597 - accuracy: 0.7785\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.3574 - accuracy: 0.7795\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3561 - accuracy: 0.7784\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3537 - accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3539 - accuracy: 0.7806\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.3520 - accuracy: 0.7813\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.3513 - accuracy: 0.7818\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3502 - accuracy: 0.7820\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3493 - accuracy: 0.7820\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3489 - accuracy: 0.7824\n",
            ">Saved models/model_43.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_13.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_23.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_33.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_43.h5\n",
            "Model: \"functional_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ensemble_13_input_13 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_input_14 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_input_15 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_input_16 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_embedding_12 (Embed (None, 20, 128)      3318272     ensemble_13_input_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_embedding_13 (Embed (None, 20, 128)      3318272     ensemble_23_input_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_embedding_14 (Embed (None, 20, 128)      3318272     ensemble_33_input_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_embedding_15 (Embed (None, 20, 128)      3318272     ensemble_43_input_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_conv1d_12 (Conv1D)  (None, 19, 300)      77100       ensemble_13_embedding_12[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_conv1d_13 (Conv1D)  (None, 18, 300)      115500      ensemble_23_embedding_13[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_conv1d_14 (Conv1D)  (None, 17, 300)      153900      ensemble_33_embedding_14[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_conv1d_15 (Conv1D)  (None, 16, 300)      192300      ensemble_43_embedding_15[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_layer_normalization (None, 19, 300)      600         ensemble_13_conv1d_12[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_layer_normalization (None, 18, 300)      600         ensemble_23_conv1d_13[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_layer_normalization (None, 17, 300)      600         ensemble_33_conv1d_14[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_layer_normalization (None, 16, 300)      600         ensemble_43_conv1d_15[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_dropout_24 (Dropout (None, 19, 300)      0           ensemble_13_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_dropout_26 (Dropout (None, 18, 300)      0           ensemble_23_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_dropout_28 (Dropout (None, 17, 300)      0           ensemble_33_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_dropout_30 (Dropout (None, 16, 300)      0           ensemble_43_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_max_pooling1d_12 (M (None, 9, 300)       0           ensemble_13_dropout_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_max_pooling1d_13 (M (None, 9, 300)       0           ensemble_23_dropout_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_max_pooling1d_14 (M (None, 8, 300)       0           ensemble_33_dropout_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_max_pooling1d_15 (M (None, 8, 300)       0           ensemble_43_dropout_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_flatten_12 (Flatten (None, 2700)         0           ensemble_13_max_pooling1d_12[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_flatten_13 (Flatten (None, 2700)         0           ensemble_23_max_pooling1d_13[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_flatten_14 (Flatten (None, 2400)         0           ensemble_33_max_pooling1d_14[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_flatten_15 (Flatten (None, 2400)         0           ensemble_43_max_pooling1d_15[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_dense_30 (Dense)    (None, 1024)         2765824     ensemble_13_flatten_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_dense_32 (Dense)    (None, 1024)         2765824     ensemble_23_flatten_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_dense_34 (Dense)    (None, 1024)         2458624     ensemble_33_flatten_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_dense_36 (Dense)    (None, 1024)         2458624     ensemble_43_flatten_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_layer_normalization (None, 1024)         2048        ensemble_13_dense_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_layer_normalization (None, 1024)         2048        ensemble_23_dense_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_layer_normalization (None, 1024)         2048        ensemble_33_dense_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_layer_normalization (None, 1024)         2048        ensemble_43_dense_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_dropout_25 (Dropout (None, 1024)         0           ensemble_13_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_dropout_27 (Dropout (None, 1024)         0           ensemble_23_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_dropout_29 (Dropout (None, 1024)         0           ensemble_33_layer_normalization_2\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_dropout_31 (Dropout (None, 1024)         0           ensemble_43_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_13_dense_31 (Dense)    (None, 2)            2050        ensemble_13_dropout_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_23_dense_33 (Dense)    (None, 2)            2050        ensemble_23_dropout_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_33_dense_35 (Dense)    (None, 2)            2050        ensemble_33_dropout_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_43_dense_37 (Dense)    (None, 2)            2050        ensemble_43_dropout_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8)            0           ensemble_13_dense_31[0][0]       \n",
            "                                                                 ensemble_23_dense_33[0][0]       \n",
            "                                                                 ensemble_33_dense_35[0][0]       \n",
            "                                                                 ensemble_43_dense_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 10)           90          concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 2)            22          dense_38[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,279,688\n",
            "Trainable params: 112\n",
            "Non-trainable params: 24,279,576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[array([[    0,     0,     0, ..., 16569, 24073, 16082],\n",
            "       [    0,     0,     0, ...,  8305, 17577,  1685],\n",
            "       [    0,     0,     0, ..., 22137, 15403,  9866],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8305,  6848,    70],\n",
            "       [    0,     0,     0, ..., 22137, 18543, 15407],\n",
            "       [    0,     0,     0, ...,  8305,  6193,  8386]], dtype=int32), array([[    0,     0,     0, ..., 16569, 24073, 16082],\n",
            "       [    0,     0,     0, ...,  8305, 17577,  1685],\n",
            "       [    0,     0,     0, ..., 22137, 15403,  9866],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8305,  6848,    70],\n",
            "       [    0,     0,     0, ..., 22137, 18543, 15407],\n",
            "       [    0,     0,     0, ...,  8305,  6193,  8386]], dtype=int32), array([[    0,     0,     0, ..., 16569, 24073, 16082],\n",
            "       [    0,     0,     0, ...,  8305, 17577,  1685],\n",
            "       [    0,     0,     0, ..., 22137, 15403,  9866],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8305,  6848,    70],\n",
            "       [    0,     0,     0, ..., 22137, 18543, 15407],\n",
            "       [    0,     0,     0, ...,  8305,  6193,  8386]], dtype=int32), array([[    0,     0,     0, ..., 16569, 24073, 16082],\n",
            "       [    0,     0,     0, ...,  8305, 17577,  1685],\n",
            "       [    0,     0,     0, ..., 22137, 15403,  9866],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  8305,  6848,    70],\n",
            "       [    0,     0,     0, ..., 22137, 18543, 15407],\n",
            "       [    0,     0,     0, ...,  8305,  6193,  8386]], dtype=int32)]\n",
            "Epoch 1/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3989 - accuracy: 0.7669\n",
            "Epoch 2/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3721 - accuracy: 0.7783\n",
            "Epoch 3/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3717 - accuracy: 0.7789\n",
            "Epoch 4/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3715 - accuracy: 0.7793\n",
            "Epoch 5/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3715 - accuracy: 0.7784\n",
            "Epoch 6/20\n",
            "485/485 [==============================] - 4s 8ms/step - loss: 0.3714 - accuracy: 0.7787\n",
            "Epoch 7/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3717 - accuracy: 0.7781\n",
            "Epoch 8/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3716 - accuracy: 0.7790\n",
            "Epoch 9/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3718 - accuracy: 0.7776\n",
            "Epoch 10/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3712 - accuracy: 0.7791\n",
            "Epoch 11/20\n",
            "485/485 [==============================] - 4s 8ms/step - loss: 0.3691 - accuracy: 0.7790\n",
            "Epoch 12/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3682 - accuracy: 0.7777\n",
            "Epoch 13/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3675 - accuracy: 0.7771\n",
            "Epoch 14/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3677 - accuracy: 0.7777\n",
            "Epoch 15/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3670 - accuracy: 0.7789\n",
            "Epoch 16/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3667 - accuracy: 0.7775\n",
            "Epoch 17/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3677 - accuracy: 0.7776\n",
            "Epoch 18/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3676 - accuracy: 0.7777\n",
            "Epoch 19/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3663 - accuracy: 0.7782\n",
            "Epoch 20/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3673 - accuracy: 0.7778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83      6315\n",
            "           1       0.95      0.56      0.70      5491\n",
            "\n",
            "    accuracy                           0.78     11806\n",
            "   macro avg       0.83      0.77      0.76     11806\n",
            "weighted avg       0.82      0.78      0.77     11806\n",
            "\n",
            "RUN:3.000000\n",
            "Accuracy: 77.985770, loss:0.365145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "                                                      URL label\n",
            "54142   GET http://localhost:8080/tienda1/publico/aute...  anom\n",
            "157946  GET http://localhost:8080/tienda1/miembros/edi...  norm\n",
            "128016  GET http://localhost:8080/tienda1/imagenes/nue...  norm\n",
            "86097   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "222387  POST http://localhost:8080/tienda1/publico/reg...  norm\n",
            "(149801, 2)\n",
            "anom    80121\n",
            "norm    69680\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "210391  POST http://localhost:8080/tienda1/miembros/ed...  norm\n",
            "26507   GET http://localhost:8080/tienda1/miembros/edi...  anom\n",
            "215663  POST http://localhost:8080/tienda1/publico/reg...  norm\n",
            "162335  GET http://localhost:8080/tienda1/publico/vaci...  norm\n",
            "176395  GET http://localhost:8080/tienda1/publico/prod...  norm\n",
            "(61978, 2)\n",
            "anom    33149\n",
            "norm    28829\n",
            "Name: label, dtype: int64\n",
            "                                                      URL label\n",
            "204392  POST http://localhost:8080/tienda1/publico/ana...  norm\n",
            "102598  POST http://localhost:8080/tienda1/miembros/ed...  anom\n",
            "195288  POST http://localhost:8080/tienda1/publico/ent...  norm\n",
            "86861   POST http://localhost:8080/tienda1/publico/reg...  anom\n",
            "148887  GET http://localhost:8080/tienda1/miembros/ima...  norm\n",
            "(11806, 2)\n",
            "anom    6315\n",
            "norm    5491\n",
            "Name: label, dtype: int64\n",
            "Loss after epoch 0: 637010.625\n",
            "Loss after epoch 1: 515026.25\n",
            "Loss after epoch 2: 475289.625\n",
            "Loss after epoch 3: 454129.25\n",
            "Loss after epoch 4: 422024.5\n",
            "Loss after epoch 5: 406694.25\n",
            "Loss after epoch 6: 398542.75\n",
            "Loss after epoch 7: 390672.25\n",
            "Loss after epoch 8: 385547.0\n",
            "Loss after epoch 9: 339680.5\n",
            "Loss after epoch 10: 325348.0\n",
            "Loss after epoch 11: 323597.5\n",
            "Loss after epoch 12: 323513.0\n",
            "Loss after epoch 13: 317758.0\n",
            "Loss after epoch 14: 315514.5\n",
            "Loss after epoch 15: 309092.0\n",
            "Loss after epoch 16: 309284.5\n",
            "Loss after epoch 17: 307508.5\n",
            "Loss after epoch 18: 305136.5\n",
            "Loss after epoch 19: 304115.5\n",
            "Loss after epoch 20: 301301.0\n",
            "Loss after epoch 21: 299107.0\n",
            "Loss after epoch 22: 308661.0\n",
            "Loss after epoch 23: 326370.0\n",
            "Loss after epoch 24: 325099.0\n",
            "Loss after epoch 25: 326314.0\n",
            "Loss after epoch 26: 323130.0\n",
            "Loss after epoch 27: 318185.0\n",
            "Loss after epoch 28: 314511.0\n",
            "Loss after epoch 29: 316844.0\n",
            "anadir.jsp\n",
            "Vocabulary size: 25923\n",
            "24376\n",
            "24376\n",
            "Create Embedding matrix\n",
            "Embedding matrix: (25924, 128)\n",
            "Build Keras model\n",
            "[10401, 11720, 68, 22087, 18502, 3095, 19162, 16778] [10401, 11720, 68, 22087, 15320, 8236, 2527, 9309, 9505]\n",
            "[18259, 11720, 68, 22087, 18502, 2329, 16506, 12447, 16014, 11834, 19352] [18259, 11720, 68, 22087, 15320, 8236, 3227, 19103]\n",
            "[18259, 11720, 68, 22087, 15320, 8236, 7759, 4987, 7237, 20157, 14391, 68] [10401, 11720, 68, 22087, 15320, 8236, 16506, 1933]\n",
            "x_train shape: (149801, 20)\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 10401 11720    68 22087 18502  3095 19162 16778]\n",
            "x_val shape: (11806, 20)\n",
            "[    0     0     0     0     0     0     0     0     0 18259 11720    68\n",
            " 22087 18502  2329 16506 12447 16014 11834 19352]\n",
            "x_test shape: (61978, 20)\n",
            "[    0     0     0     0     0     0     0     0 18259 11720    68 22087\n",
            " 15320  8236  7759  4987  7237 20157 14391    68]\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"functional_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_16 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 19, 300)           77100     \n",
            "_________________________________________________________________\n",
            "layer_normalization_32 (Laye (None, 19, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 19, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_33 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,165,894\n",
            "Trainable params: 2,847,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.6005 - accuracy: 0.6378\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.5253 - accuracy: 0.6722\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.5108 - accuracy: 0.6864\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.5026 - accuracy: 0.6908\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.4977 - accuracy: 0.6929\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.4936 - accuracy: 0.6949\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.4903 - accuracy: 0.6964\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.4876 - accuracy: 0.6960\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.4858 - accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.4843 - accuracy: 0.6990\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.4828 - accuracy: 0.6998\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.4815 - accuracy: 0.7005\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.4801 - accuracy: 0.7011\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.4797 - accuracy: 0.7011\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.4779 - accuracy: 0.7020\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.4773 - accuracy: 0.7012\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.4762 - accuracy: 0.7023\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.4762 - accuracy: 0.7024\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.4750 - accuracy: 0.7028\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.4747 - accuracy: 0.7032\n",
            ">Saved models/model_14.h5\n",
            "Model: \"functional_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_17 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 18, 300)           115500    \n",
            "_________________________________________________________________\n",
            "layer_normalization_34 (Laye (None, 18, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 18, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 9, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1024)              2765824   \n",
            "_________________________________________________________________\n",
            "layer_normalization_35 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 6,204,294\n",
            "Trainable params: 2,886,022\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.5344 - accuracy: 0.6928\n",
            "Epoch 2/20\n",
            "1171/1171 - 6s - loss: 0.4036 - accuracy: 0.7510\n",
            "Epoch 3/20\n",
            "1171/1171 - 6s - loss: 0.3868 - accuracy: 0.7628\n",
            "Epoch 4/20\n",
            "1171/1171 - 6s - loss: 0.3764 - accuracy: 0.7688\n",
            "Epoch 5/20\n",
            "1171/1171 - 6s - loss: 0.3696 - accuracy: 0.7728\n",
            "Epoch 6/20\n",
            "1171/1171 - 6s - loss: 0.3656 - accuracy: 0.7740\n",
            "Epoch 7/20\n",
            "1171/1171 - 6s - loss: 0.3614 - accuracy: 0.7762\n",
            "Epoch 8/20\n",
            "1171/1171 - 6s - loss: 0.3581 - accuracy: 0.7784\n",
            "Epoch 9/20\n",
            "1171/1171 - 6s - loss: 0.3561 - accuracy: 0.7794\n",
            "Epoch 10/20\n",
            "1171/1171 - 6s - loss: 0.3550 - accuracy: 0.7798\n",
            "Epoch 11/20\n",
            "1171/1171 - 6s - loss: 0.3526 - accuracy: 0.7805\n",
            "Epoch 12/20\n",
            "1171/1171 - 6s - loss: 0.3516 - accuracy: 0.7804\n",
            "Epoch 13/20\n",
            "1171/1171 - 6s - loss: 0.3494 - accuracy: 0.7815\n",
            "Epoch 14/20\n",
            "1171/1171 - 6s - loss: 0.3488 - accuracy: 0.7819\n",
            "Epoch 15/20\n",
            "1171/1171 - 6s - loss: 0.3474 - accuracy: 0.7832\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3465 - accuracy: 0.7841\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.3460 - accuracy: 0.7839\n",
            "Epoch 18/20\n",
            "1171/1171 - 6s - loss: 0.3454 - accuracy: 0.7839\n",
            "Epoch 19/20\n",
            "1171/1171 - 6s - loss: 0.3443 - accuracy: 0.7833\n",
            "Epoch 20/20\n",
            "1171/1171 - 6s - loss: 0.3432 - accuracy: 0.7844\n",
            ">Saved models/model_24.h5\n",
            "Model: \"functional_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_18 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 17, 300)           153900    \n",
            "_________________________________________________________________\n",
            "layer_normalization_36 (Laye (None, 17, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_37 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,935,494\n",
            "Trainable params: 2,617,222\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 6s - loss: 0.6230 - accuracy: 0.6264\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.5361 - accuracy: 0.6684\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.5195 - accuracy: 0.6817\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.5107 - accuracy: 0.6878\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.5049 - accuracy: 0.6892\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.5004 - accuracy: 0.6925\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.4965 - accuracy: 0.6942\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.4944 - accuracy: 0.6944\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.4921 - accuracy: 0.6953\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.4901 - accuracy: 0.6971\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.4892 - accuracy: 0.6970\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.4874 - accuracy: 0.6977\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.4867 - accuracy: 0.6983\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.4851 - accuracy: 0.6987\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.4849 - accuracy: 0.6986\n",
            "Epoch 16/20\n",
            "1171/1171 - 5s - loss: 0.4829 - accuracy: 0.6997\n",
            "Epoch 17/20\n",
            "1171/1171 - 5s - loss: 0.4820 - accuracy: 0.7002\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.4818 - accuracy: 0.6996\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.4809 - accuracy: 0.7005\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.4805 - accuracy: 0.7014\n",
            ">Saved models/model_34.h5\n",
            "Model: \"functional_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 20, 128)           3318272   \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 16, 300)           192300    \n",
            "_________________________________________________________________\n",
            "layer_normalization_38 (Laye (None, 16, 300)           600       \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 16, 300)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1024)              2458624   \n",
            "_________________________________________________________________\n",
            "layer_normalization_39 (Laye (None, 1024)              2048      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 5,973,894\n",
            "Trainable params: 2,655,622\n",
            "Non-trainable params: 3,318,272\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1171/1171 - 5s - loss: 0.5697 - accuracy: 0.6599\n",
            "Epoch 2/20\n",
            "1171/1171 - 5s - loss: 0.4220 - accuracy: 0.7444\n",
            "Epoch 3/20\n",
            "1171/1171 - 5s - loss: 0.3990 - accuracy: 0.7591\n",
            "Epoch 4/20\n",
            "1171/1171 - 5s - loss: 0.3892 - accuracy: 0.7646\n",
            "Epoch 5/20\n",
            "1171/1171 - 5s - loss: 0.3815 - accuracy: 0.7679\n",
            "Epoch 6/20\n",
            "1171/1171 - 5s - loss: 0.3763 - accuracy: 0.7702\n",
            "Epoch 7/20\n",
            "1171/1171 - 5s - loss: 0.3721 - accuracy: 0.7722\n",
            "Epoch 8/20\n",
            "1171/1171 - 5s - loss: 0.3686 - accuracy: 0.7741\n",
            "Epoch 9/20\n",
            "1171/1171 - 5s - loss: 0.3658 - accuracy: 0.7756\n",
            "Epoch 10/20\n",
            "1171/1171 - 5s - loss: 0.3649 - accuracy: 0.7762\n",
            "Epoch 11/20\n",
            "1171/1171 - 5s - loss: 0.3619 - accuracy: 0.7766\n",
            "Epoch 12/20\n",
            "1171/1171 - 5s - loss: 0.3606 - accuracy: 0.7787\n",
            "Epoch 13/20\n",
            "1171/1171 - 5s - loss: 0.3588 - accuracy: 0.7790\n",
            "Epoch 14/20\n",
            "1171/1171 - 5s - loss: 0.3581 - accuracy: 0.7785\n",
            "Epoch 15/20\n",
            "1171/1171 - 5s - loss: 0.3562 - accuracy: 0.7796\n",
            "Epoch 16/20\n",
            "1171/1171 - 6s - loss: 0.3550 - accuracy: 0.7805\n",
            "Epoch 17/20\n",
            "1171/1171 - 6s - loss: 0.3535 - accuracy: 0.7801\n",
            "Epoch 18/20\n",
            "1171/1171 - 5s - loss: 0.3521 - accuracy: 0.7811\n",
            "Epoch 19/20\n",
            "1171/1171 - 5s - loss: 0.3510 - accuracy: 0.7819\n",
            "Epoch 20/20\n",
            "1171/1171 - 5s - loss: 0.3510 - accuracy: 0.7817\n",
            ">Saved models/model_44.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_14.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_24.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_34.h5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            ">loaded models/model_44.h5\n",
            "Model: \"functional_49\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ensemble_14_input_17 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_input_18 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_input_19 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_input_20 (InputLaye [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_embedding_16 (Embed (None, 20, 128)      3318272     ensemble_14_input_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_embedding_17 (Embed (None, 20, 128)      3318272     ensemble_24_input_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_embedding_18 (Embed (None, 20, 128)      3318272     ensemble_34_input_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_embedding_19 (Embed (None, 20, 128)      3318272     ensemble_44_input_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_conv1d_16 (Conv1D)  (None, 19, 300)      77100       ensemble_14_embedding_16[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_conv1d_17 (Conv1D)  (None, 18, 300)      115500      ensemble_24_embedding_17[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_conv1d_18 (Conv1D)  (None, 17, 300)      153900      ensemble_34_embedding_18[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_conv1d_19 (Conv1D)  (None, 16, 300)      192300      ensemble_44_embedding_19[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_layer_normalization (None, 19, 300)      600         ensemble_14_conv1d_16[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_layer_normalization (None, 18, 300)      600         ensemble_24_conv1d_17[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_layer_normalization (None, 17, 300)      600         ensemble_34_conv1d_18[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_layer_normalization (None, 16, 300)      600         ensemble_44_conv1d_19[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_dropout_32 (Dropout (None, 19, 300)      0           ensemble_14_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_dropout_34 (Dropout (None, 18, 300)      0           ensemble_24_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_dropout_36 (Dropout (None, 17, 300)      0           ensemble_34_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_dropout_38 (Dropout (None, 16, 300)      0           ensemble_44_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_max_pooling1d_16 (M (None, 9, 300)       0           ensemble_14_dropout_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_max_pooling1d_17 (M (None, 9, 300)       0           ensemble_24_dropout_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_max_pooling1d_18 (M (None, 8, 300)       0           ensemble_34_dropout_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_max_pooling1d_19 (M (None, 8, 300)       0           ensemble_44_dropout_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_flatten_16 (Flatten (None, 2700)         0           ensemble_14_max_pooling1d_16[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_flatten_17 (Flatten (None, 2700)         0           ensemble_24_max_pooling1d_17[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_flatten_18 (Flatten (None, 2400)         0           ensemble_34_max_pooling1d_18[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_flatten_19 (Flatten (None, 2400)         0           ensemble_44_max_pooling1d_19[0][0\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_dense_40 (Dense)    (None, 1024)         2765824     ensemble_14_flatten_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_dense_42 (Dense)    (None, 1024)         2765824     ensemble_24_flatten_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_dense_44 (Dense)    (None, 1024)         2458624     ensemble_34_flatten_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_dense_46 (Dense)    (None, 1024)         2458624     ensemble_44_flatten_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_layer_normalization (None, 1024)         2048        ensemble_14_dense_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_layer_normalization (None, 1024)         2048        ensemble_24_dense_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_layer_normalization (None, 1024)         2048        ensemble_34_dense_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_layer_normalization (None, 1024)         2048        ensemble_44_dense_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_dropout_33 (Dropout (None, 1024)         0           ensemble_14_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_dropout_35 (Dropout (None, 1024)         0           ensemble_24_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_dropout_37 (Dropout (None, 1024)         0           ensemble_34_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_dropout_39 (Dropout (None, 1024)         0           ensemble_44_layer_normalization_3\n",
            "__________________________________________________________________________________________________\n",
            "ensemble_14_dense_41 (Dense)    (None, 2)            2050        ensemble_14_dropout_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_24_dense_43 (Dense)    (None, 2)            2050        ensemble_24_dropout_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_34_dense_45 (Dense)    (None, 2)            2050        ensemble_34_dropout_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "ensemble_44_dense_47 (Dense)    (None, 2)            2050        ensemble_44_dropout_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8)            0           ensemble_14_dense_41[0][0]       \n",
            "                                                                 ensemble_24_dense_43[0][0]       \n",
            "                                                                 ensemble_34_dense_45[0][0]       \n",
            "                                                                 ensemble_44_dense_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 10)           90          concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 2)            22          dense_48[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 24,279,688\n",
            "Trainable params: 112\n",
            "Non-trainable params: 24,279,576\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[array([[    0,     0,     0, ..., 20157, 14391,    68],\n",
            "       [    0,     0,     0, ...,  8236, 16506,  1933],\n",
            "       [    0,     0,     0, ..., 19108, 14027,  1248],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  2329,  5166,    68],\n",
            "       [    0,     0,     0, ..., 17263, 15518, 12159],\n",
            "       [    0,     0,     0, ..., 14027, 22546, 13738]], dtype=int32), array([[    0,     0,     0, ..., 20157, 14391,    68],\n",
            "       [    0,     0,     0, ...,  8236, 16506,  1933],\n",
            "       [    0,     0,     0, ..., 19108, 14027,  1248],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  2329,  5166,    68],\n",
            "       [    0,     0,     0, ..., 17263, 15518, 12159],\n",
            "       [    0,     0,     0, ..., 14027, 22546, 13738]], dtype=int32), array([[    0,     0,     0, ..., 20157, 14391,    68],\n",
            "       [    0,     0,     0, ...,  8236, 16506,  1933],\n",
            "       [    0,     0,     0, ..., 19108, 14027,  1248],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  2329,  5166,    68],\n",
            "       [    0,     0,     0, ..., 17263, 15518, 12159],\n",
            "       [    0,     0,     0, ..., 14027, 22546, 13738]], dtype=int32), array([[    0,     0,     0, ..., 20157, 14391,    68],\n",
            "       [    0,     0,     0, ...,  8236, 16506,  1933],\n",
            "       [    0,     0,     0, ..., 19108, 14027,  1248],\n",
            "       ...,\n",
            "       [    0,     0,     0, ...,  2329,  5166,    68],\n",
            "       [    0,     0,     0, ..., 17263, 15518, 12159],\n",
            "       [    0,     0,     0, ..., 14027, 22546, 13738]], dtype=int32)]\n",
            "Epoch 1/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3980 - accuracy: 0.7686\n",
            "Epoch 2/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3651 - accuracy: 0.7793\n",
            "Epoch 3/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3650 - accuracy: 0.7785\n",
            "Epoch 4/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3649 - accuracy: 0.7801\n",
            "Epoch 5/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3651 - accuracy: 0.7779\n",
            "Epoch 6/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3645 - accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3638 - accuracy: 0.7786\n",
            "Epoch 8/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3645 - accuracy: 0.7785\n",
            "Epoch 9/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3642 - accuracy: 0.7782\n",
            "Epoch 10/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3639 - accuracy: 0.7798\n",
            "Epoch 11/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3635 - accuracy: 0.7792\n",
            "Epoch 12/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3629 - accuracy: 0.7803\n",
            "Epoch 13/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3626 - accuracy: 0.7809\n",
            "Epoch 14/20\n",
            "485/485 [==============================] - 3s 7ms/step - loss: 0.3621 - accuracy: 0.7806\n",
            "Epoch 15/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3625 - accuracy: 0.7807\n",
            "Epoch 16/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3623 - accuracy: 0.7795\n",
            "Epoch 17/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3630 - accuracy: 0.7807\n",
            "Epoch 18/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3626 - accuracy: 0.7786\n",
            "Epoch 19/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3624 - accuracy: 0.7806\n",
            "Epoch 20/20\n",
            "485/485 [==============================] - 4s 7ms/step - loss: 0.3625 - accuracy: 0.7799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.94      0.82      6315\n",
            "           1       0.90      0.60      0.72      5491\n",
            "\n",
            "    accuracy                           0.79     11806\n",
            "   macro avg       0.82      0.77      0.77     11806\n",
            "weighted avg       0.81      0.79      0.78     11806\n",
            "\n",
            "RUN:4.000000\n",
            "Accuracy: 78.527867, loss:0.361182\n",
            "Max Accuracy: 78.527867,Min Accuracy: 77.672370,Avg Accuracy: 78.121294, Avg loss:0.363182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEjCAYAAAAi6PocAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeYAldX33+/enqs45vc7aw7DM0sAM6gCiZAR5VMQ1kCgmMS4kT4xJrtw8CU/0MSEPXnO9Ljc3GuOSKFlQcVdwxYliEBCEEEFmXFgGZhiWYYZt9p6eXs45VfW9f1Sd7tM93dPN9HK6z3xfWtT2q6pvVZ/5/qrq1KmfzAznnHPzX9DoAJxzzk0PT+jOOdckPKE751yT8ITunHNNwhO6c841CU/ozjnXJDyhO+dck/CE7pqKpMckvbrRcTjXCJ7QnXOuSXhCd01PUknSJyU9mXeflFTK53VJ+r6kA5L2SbpdUpDP+9+SnpDUK2mLpFc1dk+cO7Ko0QE4NwveC7wYeAFgwPeAvwH+b+AvgZ3AsrzsiwGT9BzgMuBFZvakpG4gnN2wnXt2/AzdHQt+H/igme0ys93AB4A/yOdVgROA1WZWNbPbLXvBUQKUgHWSCmb2mJk93JDonZskT+juWHAisL1ufHs+DeCjwDbgR5IekXQFgJltA94FvB/YJekaSSfi3BzmCd0dC54EVteNr8qnYWa9ZvaXZnYKcDHw7tq9cjP7mpm9NF/WgI/MbtjOPTue0F0zKkhqqXXA14G/kbRMUhfwPuArAJJeJ2mNJAE9ZLdaUknPkfTK/MvTQWAASBuzO85Njid014yuJ0vAta4F2AjcA9wL/Bz4f/Oya4GbgEPAT4F/NrNbyO6ffxjYAzwNHAe8Z/Z2wblnT97AhXPONQc/Q3fOuSbhCd0555qEJ3TnnGsSntCdc65JeEJ3zrkm4QndOeeahCd055xrEp7QnXOuSXhCd865JuEJ3TnnmoQndOecaxKe0J1zrkl4QnfOuSbhCd0555qEJ3TnnGsSntCdc65JeEJ3zrkmETVqw11dXdbd3d2ozTvn3Ly0adOmPWa2bKx5DUvo3d3dbNy4sVGbd865eUnS9vHmTeqWi6QLJW2RtE3SFeOUebOkzZLul/S1ow3WOefc0ZkwoUsKgSuBi4B1wCWS1o0qs5asRfSXmNnpwLtmIFYAHrp1A7f89ws59NSOmdqEc87NS5M5Qz8H2GZmj5hZBbgGeMOoMu8ArjSz/QBmtmt6wxy25Z7bWHDvM2y56ELu+eInMbOZ2pRzzs0rk0noJwH1p8M782n1TgNOk3SHpDslXThdAY62es0fsPH8v2PLmgsIP/wZbnvza+jd8chMbc455+aN6XpsMQLWAhcAlwCfkbRodCFJl0raKGnj7t27j2pDi3tvZrm2sL/rjdz2ig9Q3dXFQ7/5On511d9jaTqVfXDOuXltMgn9CWBl3fiKfFq9ncAGM6ua2aPAVrIEP4KZXWVm681s/bJlYz51M6HvLn0dP+zYz4u7PsPC4BBbnncpm85+NwOfvYX//J1X0vPwlqNar3POzXeTSeh3A2slnSypCLwV2DCqzHVkZ+dI6iK7BTMj90Hecs4q1rz8rfwf0du4q3MrZy/8CkHbYjadfTk7C6/jgbe+g19+6kNYkszE5p1zbs7SZL5UlPQbwCeBELjazP5W0geBjWa2QZKAjwEXAgnwt2Z2zZHWuX79epvKc+j9lZhvbdrJ5297iPN6fsRrKlUePPRaUotY8cRtLNLPeME/fIKFzzn9qLfhnHNzjaRNZrZ+zHmNekpkqgm9JkmNGzc/zRdu28IZO/6dFwy2s33gfMJ4kFU7buD4Vy/lhe96LyoUpiFq55xrrKZO6PV+/vh+vvyT+1lx/3dZ1n8SvZUXUBrcx/E9N/GSD1zK4uefPa3bc8652XbMJPSax/f28/Wf/IqOu7+LDjwPs9V09D7O6lXbOf8D7yEoFmdku845N9OOuYRe09Nf5du3baT31m9R2HseFi5hQe/9rL94Nae8+nyKSxaS3f53zrn54ZhN6DWVOOUHt/0nj13377T0v5w0agMgqh6iUD1AlB4kVB9RsUxLe8CCroUsXb2SE04/lUUnn0i0eDEK/E3DzrnGO+YTeo2Zcc33v8xTN/2McLCVKO4kSBcSsBALFpEUFhy2TJBUKFZ6KMQHCNODBOojLFQJSiJqCSm1t9C6cAEdXUvoXN7FwhOPZ8HyJZQWLSJob/MrAOfctPKEPoHBeJCdB3by6M7NPPHIw/Q+/gzx3jL0hgSDbQRxJ6EtRCwiDRdCcOQnZoKkTBQPEMUDBOkAQTqIbACpjDSIgiqECUFoKIIgCghLAVGpQKG1RKm9lZbODtoXLKRj6RI6liyh47illBZ1EbS3ozCcpSPjnJtrjpTQG/Y+9LmkJWphTdca1nStgReMX66vcohd+x/myScfYd/+Axzce4D+fYeo9lRI+mJsQFglQNUCSVCkEpVQ2oJoA5aCWkmD1sMrhBQYyLsDY225F+glSB8iSKoEaQVZnHdVZFUgQVSBOOuUDPeDBIIUlKIohcBQCAohCCEIA4JCQBAFRMWQsBARlQpELUVKpRLF1hZKbS20tLbR2tlOW1sHbZ2dtHS0U2hpgyCCsABhMds3vz3lXEN4Qn8W2osdnLz8LE5eftZRr6OSVDg40Muhvn4O9B6g58B+Du3bR/+BHsq9h6geGiQeGCQdqJJUUqikUAUSYYSkFmIKURqCRUCE8j60AgVQBIowRZgKmAqkQQTKE22ad9Wj3Yv+rLMUWYKG+iM7LEHU9UlHDpOCDCzJ+mSVDmTDyqeZbGgYWd4B5NODrG8CyVCQzZeAABQIKavAFGT1jQIRBoIgIAhFGISEYUAQ5v0oJAxDojAijELCKKIQFQgLBaIoIioWs+FCkahQICoVKRRKFEolgmKRoFBEhQJBoYSiiCAKIYwIwgIEIQrCLEAFeaDOTZ0n9FlWDIt0dSylq2MpLF858QLTILWUclymXB6k78ABevftYaBvgMFDvZT7B6gM9FMdKFMZLBMPxsTVKmklJq3EJLFhcYrFRpajDVJBKswEI7pgqLMsk2IWIgWkhECYnc1TInvrRK0TppAsC2fTbMx+Vs5qibCe5R1kv1WedfWXWZNgKbK8kjJDpNm0WmVWm4chq6vkMLDaztZ2uP62aTasI8zDausaXu/weFo3XpuXZHEMVbjDL8GzWl00VMnWpteNC1AeUV155TFllbXl9ZoNzVN9pa26cer//MMbyf4HBBo1Pf+v6qbllb/llT0Y+UcMaicAeWfB8DCBQBAEAQoCFGSfRQXKp4VIIgiUDQcBCvNpYTYeBgErz3g+K0//NaabJ/RjQKCA1kIrrYVWFnUshhUnNzqko5ZaSjWuUo2rlAfKlCsVKoMVquUq5UqVuFKhUompxhWScky1WiWpxlQrVZI4Ia1WsgorjrGkSlpNSJMqaRJjSUKaJJCmWJyQpimkCWlqkKbZ9NQwS/O8Ztn7+FOyBGzKkrMJ0mxclqWgLGflfZTn41riyTvLLykMIBhKRSPmUevn6xmiCfqjpwV5kg2B7OrNGFmJDk2rlZOGK+pRCXKoX0vcedwGwxW+yE4C4PAK+Riz9T+/xds/5QndHeMCBZQKJUqFEh2tHY0Ox41iZnnFGJOmCZYmWJKSJlWSJCVJ4qxiTRPiOCZOjbiakCQJSZJSjRPMUuI4JY5jLEmJ05Q0zeaniREnad6wjWGWXT2kSXa1YSRgRmoGaYJhYCmpZVdAYFi+vKVpViknecWcWFZh5xV4Vsayyjklr8yBJB1ab20dtfVm0+quotI0vyDKt23ZvNXnHeHLuinwhO6cmzaS8u8MPLU0wrF93eOcc03EE7pzzjUJT+jOOdckJpXQJV0oaYukbZKuOEK5N0oySWP+isk559zMmTChSwqBK4GLgHXAJZLWjVGuE3gncNd0B+mcc25ikzlDPwfYZmaPmFkFuAZ4wxjlPgR8BBicxvicc85N0mQS+knAjrrxnfm0IZLOBlaa2Q+OtCJJl0raKGnj7t27n3WwzjnnxjflL0UlBcDHgb+cqKyZXWVm681s/bJly6a6aeecc3Umk9CfAOpfOrIin1bTCZwB3CrpMeDFwAb/YtQ552bXZBL63cBaSSdLKgJvBTbUZppZj5l1mVm3mXUDdwIXm9nceNm5c84dIyZM6GYWA5cBNwAPAN8ws/slfVDSxTMdoHPOucmZ1AsXzOx64PpR0943TtkLph6Wc865Z8t/Keqcc03CE7pzzjUJT+jOOdcklL0ovgEblnYD249y8S5gzzSGM908vqnx+KZursfo8R291WY25g95GpbQp0LSRjObs8+5e3xT4/FN3VyP0eObGX7LxTnnmoQndOecaxLzNaFf1egAJuDxTY3HN3VzPUaPbwbMy3vozjnnDjdfz9Cdc86NMqmf/s+Erq4u6+7ubtTmnXNuXtq0adOe8R5bbFhC7+7uZuNGfyGjc849G5LG/f3OtDUSLenNkjZLul/S1442WOecc0dnwjP0ukaiX0PW/NzdkjaY2ea6MmuB9wAvMbP9ko6bqYCdc86NbboaiX4HcKWZ7Qcws13TG6ZzzrmJTEsj0cBpwGmS7pB0p6QLpytA55xzkzNdX4pGwFrgArI2R2+TdKaZHagvJOlS4FKAVatWTdOmnXPOwfQ0Eg3ZWfsGM6ua2aPAVrIEP4KZXWVm681s/bJlYz5145xz7ihNuZHo3HVkZ+dI6iK7BfPINMbpnHNuAtPVSPQNwF5Jm4FbgMvNbO9MBe2cc+5wDXuXy/r1681/WOScc8+OpE3jvat93r3LZSAe4LadtzU6DOecm3Ma9tP/o/WZn3+WH955Kz2/2cPrT319o8Nxzrk5Y94l9LN3vpZg8/P4YuUaojdGXHTyRY0OyTnn5oR5d8vlRctu5cTWB3nFtt/jS9/cwI3bb2x0SM45NyfMu4R+3a7j+bWBT7Gi9ee89JE38aWvf59bHr+l0WE551zDzbtbLuu3bqXv1pC1Z3yeYEUZHnsDX/rK9QR/EPDylS9vdHjOOdcw8+4M/eR3XUb7b1yE7ktZde836C7dyvrHL+KrX/wRdzxxR6PDc865hpl3CT1obWXVx/6BZX/91xSerHLST6/j1OhGztr5Kr722Zu568m7Gh2ic841xLxL6ACS6PrjP2L1568mslZO+skG1tj1rHvqpXzt337Mxqf8B0vOuWPPvEzoNe0vfjGnffc7hKtOZcVPfsCage9x2jPn8vV//gm/eOoXjQ7POedm1bxO6ADFFSfx3G9dS+uvX8Squ37E2r3f5pTdL+Trn76de56+t9HhOefcrJn3CR2y++onf/JjLLn8clbcdwtrd3yD1XvP4Jp/vJ37nt488Qqcc64JzLvHFscjieV/8se0r3se6Z9fRlCuYmsu4dpP3EHwv8S645/X6BCdc25GNcUZer2O887jOf++gePDnax74EssP3Ay3/jYT3ngqa2NDs0552ZU0yV0gMJJJ7Huuus4aV0bZ26+mmUHV/Ktj/6ULU9ta3Rozjk3YyaV0CVdKGmLpG2SrjhCuTdKMkljvqt3NgWtrZz2z//CqZe8hDPvu4qlh47nur+7iwd3eFJ3zjWnCRO6pBC4ErgIWAdcImndGOU6gXcCc+aXPZJY8Wd/zll/dxlnbPk3Fgws5fq/u5tfbvPbL8655jOZL0XPAbaZ2SMAkq4B3gCMfnzkQ8BHgMunNcJpsPD8l3PeV07F3vEuHljxR/znRx/gpuItVNoGSRcVaF++lBNXreasU7tZu/I4wqgp70Q555rcZBL6ScCOuvGdwLn1BSSdDaw0sx9IGjehS7oUuBRg1apVzz7aKSisXMHLvvMl9I7/k2cGzmKgZSmDfcdT7emE7bDnZ/3czGZusl+RqodqoYe4dRBbXKBj6WJOWHkKp53azamrF9NWapqHg5xzTWTKmUlSAHwcePtEZc3sKuAqyNoUneq2n62grY3zv/plqs88Q3XbZqrb7mPX1i3s2rGfvoOiWukgYRHlliUMtixlsLSCysGFsB2e/nkvT3MvP7EEUw9p0E8aDpBGFawUQ4sRtRdoaSvSuaCDxYsWsWz58Sw//gSWLV9GSzFC0mzvsnPuGDKZhP4EsLJufEU+raYTOAO4NU9YxwMbJF1sZnPypSqF5cspLF8OL3kFC4G1dfOsWqX69NNUH3+Mga33smvrjezdsY+BgwFJuZ0kWEy5tJhqoT3vFlGN2okLbQAkwIG8e5QeoAfsHrA+TH2YDmHBAIQVCKsQVVEhISgYYQtErSGtLRFtLUU6WltY0NHKkgULWLJwMQs6F1JoaYdCK0QtWVdogagVwgJ4heHcMW0yCf1uYK2kk8kS+VuB36vNNLMeoKs2LulW4K/majKfiAoFiitXUly5kvaXvGx4x3Lp4CDx00+T9PaS9Bwk7jlA/54n6NvzFAf39HBofx+D/QnxoEiqBdK0REorpnbiKK8EokUkUYk4bCEJS6Dsnn2Sd2WyCuEw6UGw3XmJKhCDqogqphgUI1UhiEEJCmIIUxQkBFFKEEJQgLAgooLyfkihFFIoFCiWIkrFIqVSidaWEi2trbS3ttPe0UFbSxuFYntekRQhLEFUyiqSsOQVinNzwIQJ3cxiSZcBNwAhcLWZ3S/pg8BGM9sw00HOJUFLC8Xu7hHTFk1iOTPDBgZIentJDx4k7e8n7e+neqiPvgP76D1wkIMH+ujv7WPw0CDVgQpxOSGtGmksLIkwi8AKmIoYIRBhQYFUEWnQShpEeVcgDSIsH06CAslUd9z6kB1AaRVZjIjBEiDOu2RE35SAsoolG867IMGUosBAKQQGInveKh9WAIRCYfakElGAAqEoIAgDFIWEYUAYhIRhSBRGBFFIIYoohAWiQkQhKlCIIoqFIoUoohQVKRYKtEQlCoWIYrFIWAgJooggjAiiCEUhQVQgKIQoLEAQQRCCwny4Nu4Vl5ubZDbrt7KB7B76xo3z8iR+TrE0xcplrFwmzftWLpMOlrFKmXign77eQxw6eJBDvX0M9g8w2D9ItRpTrSQk1ZQ4TkjihDQ2LEmxBCwxLBVmwizALAALsorEIkBgIVkdn3VGCIryfogpwhQOVy4KhyqZOc/SvMJKEcnQMCQYKWAo72cd+XwDM6Ssj/J1YWiobF6ZkebrT4fGpfrhZGiehjpDSjGR/QmUrZm68aHpAiRMGho3CSQUZPWSgtqwUCCCQIQBKAgIgoAgEEEQEAYBCiEKo3wZDS2DDBQMr48sBoUa+t5IgSBQVkZZxRyGEUEQEUQBgULCUASEBMq2FwRRHk9IpJBQAUEYEhKiMCSKIsIgREF2hRkGUVZJK8gq3iBECiEM85jD7GwhDFEQoSBAYTTvKmhJm8xszN/6+OMa85yCALW2Qmsr4ThlFsxqRCNZkmCVyogurVRIKlXiSky1XCWpxFSqFeJylUqlQrVcplqJiatV4kqVuFwmqVZI4ipppZr1k4QkSYb7aYqlKUmSYpZk+ThNSc2w1CC17CoJILU8ZwYoz3RKlQ/n0whQXomJrJ9fRuRdlihrmdSULT962lCmrRs3BUCU9RVgCjEFeRdmFV8+no4xv3aLbkp/lymvoRGM4SvC6VxtXrlaXaU7uhI2Y0QlbnWVMwYjKndDNvb0Wte+6gn++/vfP737gSd0N8MUhkMVjjucpSkkCZYkQ31LEiyOSZOUaqVCpVqhUilTKVeoVitUymVIsgqMNEse2XBaNz3JK7EUkrxCq81PYpI0Ia5WSasJcRKTJClpkm0zqyBrlWWKpUaapJilpImRpgnkqS7bCbLxob6RVWJ53iO/iqiVtXwgjymLnywJ1rrU8guZfAX5fmJZuaH11VYHYNmVCHXzMIbOwM1UK5ZX2vk+KL98Gaoola9/VIVMdsVhBEP7PH4X5FdOY8+PKjNTpXpCd66BFAQQBKgw9m2o0izH4+a3ht1Dl7Qb2H6Ui3cBe6YxnOnm8U2Nxzd1cz1Gj+/orTazZWPNaFhCnwpJG8f7UmAu8PimxuOburkeo8c3M/ylJc451yQ8oTvnXJOYrwn9qkYHMAGPb2o8vqmb6zF6fDNgXt5Dd845d7j5eobunHNulIY9h97V1WXdo96J4pxz7sg2bdq0Z7zHFhuW0Lu7uzmad7n0P3gz/T/5OF2XfAYWnDgDkTnn3Nwladzf70xbI9GS3ixps6T7JX3taIOdyKdvup1PPfpyfvZPv07lnu/M1Gacc27emfAMva6R6NeQNT93t6QNZra5rsxa4D3AS8xsv6TjZirg5/atYue+k/ivnnXc+d1rePOv/p3j3/SP0NLIV1A551zjTeYMfaiRaDOrALVGouu9A7jSzPYDmNmu6Q1z2Kte9lzO2/4Zlu1/gvCpP+ZzvziXmz/xOtJH75ipTTrn3LwwmYQ+ViPRJ40qcxpwmqQ7JN0p6cLpCnC09v/23zjrui/z6vV9POehr7P04Ao2b38vH7/6azz5vSsgrszUpp1zbk6brscWI7KmOS8ALgE+I+mwhnwkXSppo6SNu3fvPuqNBa2tLP+rd/PSf7mc8/u/zfJd99K6+4185ebT2fDxt8DuLUe9buecm68mk9AnaiQasrP2DWZWNbNHga2MbHsZADO7yszWm9n6ZcvGfOrmWWk57TSe95XP8ZpLVnP6Q59ncW8bjz/85/z9x7/Ejpv/cfhlzM45dwyYTEIfaiRaUpGskejR7YheR3Z2jqQuslswj0xjnONSELD4TW/ipd/4JK9Ycjcrnryd9n2v4FvfPolrPvan0Pv0bIThnHMNN2FCN7MYqDUS/QDwjVoj0ZIuzovdAOyVtBm4BbjczPbOVNBjiZYuZc3HPsxr3nsRZ+74Iot7y+zd9hb+/gNf5JE7ZuwpSuecmzOaspHotFLh8U//K/fduJ3HV76WJKjQufa/eNufXUHQunBGtumcc7PhSI1EN+W7XIJike53/wWv+efLWLf/WhYfeIq+h17DJ674Gg/e9YNGh+ecczOiKc/Q65kZ26/5Nvd/4SZ2rHw9cRgSrvwlp65ZyqoVq1i9Zh0ty05EYTjjsTjn3FQd6Qy96RN6TXXffm6+/H0cPNDN7mUvHDHPbAAL9qNiD8WOQRYvCzlx+WJWr1jJ4tWraTtxJYqKsxarc86NxxN6nQdvvJ0Hv/hl1NNHWI0I0k6qxSUMtuRdaQlxoW3kQlYlYB9heIBSaz8LFonOha0sWtLJ4sWLaVu0kNLCBZQWLaa0ZClhayuSZn3fnHPNzxP6EZgZ/fsO8My2x9nz6OPs2b6N3h2Pku7rIeoXYdyGtIhqYTjpV4sTvDfGqgQ2gKyfQIMoKBOGFcJiQrEkWjoiiq1FWttbaF/QTsfCTjoXLaKlo4NCWytRWxuF9nYKbW0EhcArB+fckCMl9Ia9PneukET70sWcsnQxp5x71phlzIye3fvYvmUr2x+6hwM77yLp6YW+ATSYEFQgiEOCpEhgLUALohXURhK2EkdtxNFiyoU2+qJW7MBY9+v78m70xhNkFWTlrE/WoRgUIyUQJChIUJCiyAhCIyiIsCCiYkBUiii0Fim2lWhpb6W1s43WlhZaW0sUSyVKxRZaWlsollqJikXClhJBFGW3mcIiBBF4peLcnHfMJ/TJkMSi45ay6LjzOOtl5016OTOj99AAu555kj27nmLfnqfp2/0I5b27SfsHSQfL2GAVK6eoaigRVEOCNEBphKwAVkQUgGLWqYipiKmABS2kQYEkiPJ+gTQokIbP5n5/Oe96RgWfIovBYkQMVs37MRADCZBmfRmQIqXZtLwvpdk8GZKBUiSy4cBQQF0fggAUgEKhQCgSYRgQhEJRQFgICaKQqBgQRBFhISCMIoIoIioWCAshhVJEWCgQhSGFKCKKQqKoQBRGhGFIGEUUogJRWCSMihQKJcKoRBgVUBhllVet80rMzTOe0GeQJBZ0trGgcw1r1qyZ1nWbGVapMNjXT29vD4d6e+nrO8jgoUP0H9rHYG8PyaFeKn39xP1l0sEySbmKVWMoJ9hQPhakgjQAq3UhWIgsxBSCRaAICIEIU0T2xGuAEVLLyKYsI5tCTAFp3fBwF+adsnVrNp6cTYFJvrTNUsCyzgzVhmvrsWw8m57m5cfr7PBxpRhpbWPZujQ8bOQVXm2+Rt0S1fCyyivSWqVZX364Ms3WZxgK8nUFBghJmLLPaRaEINDQPJSPKxsfmiZls4LhIkFQmyYCQRhk6w2DrHIOBGEkwiAgkAiCvDIO8so5CgnDAEVZZRxEQVbpFkPCqJBVzmFEUCxSjAoEUZhtMwiHYpMCRNbPD0LeU914Pq22X0GQ71Jtv4J8XvYr9Fr5oWWH+sFwF+Sf4zlwAuAJfZ6ShEol2kol2pYsZnmjA8pZkmBJAtVqNhzHpNUqlcog5fIglcEBBssDVCtVqnGVcrlCtVylWi5TrQySlGOScpm4WiWpxli1ShInJHGMxQlWTbP1pgZpmldMaZ4zLZ9OVkmZgSnPpcpzprIOhvP0UM7UqGl1lU1tGfJ/0Fb7xx6M7DRymhHUVXgCQlCEZakHQ3nOqA0r3/xw8hirjKERFSXKtpVVlFllWqtc5z8Dqnk3MMubrlXM2bAO/9AMVfJA3fxaGctnjZze3vVz3vbhD057uJ7Q3bRSGGbP9BdH3vYpAh2NCWnOMsuuAkizM3+rDY8xXl82TVLSNK/YzLAkxdKskrMkIU5ikiQhTROSpEqcxKTVrFJMqglxtYylCWmSkCYxliQkSYLVhi3J1pnE2fx8vWkaY/l2UzPS1PJQU5LUSC3bp2y6kQAYJHlONCMvQ7ZOahOyccyy/JkdnBG5tHZRY2bIapU1yIz6HFsbF3XD+TYD6saBocq5dtaeV5hDFW3dtKFh1U4IVBfcyDRem5ZfbtVCy5fIxls6Zib1ekJ3rkGGb2tkVwKNv2B3811T/vTfOeeORZ7QnXOuSXhCd865JuEJ3TnnmsSkErqkCyVtkbRN0hVHKPdGSSZpzJ+lOuecmzkTJnRJIXAlcBGwDrhE0roxynUC7wTumu4gnXPOTWwyZ+jnANvM7BEzqwDXAG8Yo9yHgI8Ag4TvL3QAABv3SURBVNMYn3POuUmaTEI/CdhRN74znzZE0tnASjM7YnNAki6VtFHSxt27dz/rYJ1zzo1vyl+KKntxwseBv5yorJldZWbrzWz9smXLprpp55xzdSaT0J8AVtaNr8in1XQCZwC3SnoMeDGwwb8Ydc652TWZhH43sFbSyZKKwFuBDbWZZtZjZl1m1m1m3cCdwMVm1vjWK5xz7hgyYUI3sxi4DLgBeAD4hpndL+mDki6e6QCdc85NzqRezmVm1wPXj5r2vnHKXjD1sJxzzj1b/ktR55xrEp7QnXOuSXhCd865JiGzw9vamJUNS7uB7Ue5eBewZxrDmW4e39R4fFM312P0+I7eajMb84c8DUvoUyFpo5nN2efcPb6p8fimbq7H6PHNDL/l4pxzTcITunPONYn5mtCvanQAE/D4psbjm7q5HqPHNwPm5T1055xzh5uvZ+jOOedGmdRP/2dCV1eXdXd3N2rzzjk3L23atGnPeI8tNiyhd3d3s3Gjv5DROeeeDUnj/n5n2hqJlvRmSZsl3S/pa0cbrHPOuaMz4Rl6XSPRryFrfu5uSRvMbHNdmbXAe4CXmNl+ScfNVMDOOefGNl2NRL8DuNLM9gOY2a7pDdM559xEpqWRaOA04DRJd0i6U9KF0xWgc865yZmuL0UjYC1wAVmbo7dJOtPMDtQXknQpcCnAqlWrpmnTzjnnYHoaiYbsrH2DmVXN7FFgK1mCH8HMrjKz9Wa2ftmyMZ+6mVDP4CH+beN1R7Wsc841syk3Ep27juzsHEldZLdgHpnGOIf8xbc/yS03/YhP3/XdmVi9c87NW9PVSPQNwF5Jm4FbgMvNbO9MBPz2lt/lZY/9LnfefBs/2PKzmdiEc87NS9PSSLRlL4R5d97NqHPXwZ4fP855j7+eL1z3ZVb+4XE8//jumd6sc87NefPuXS6D136EdT/+Bxamj3P+o2/gfV/5GE/39jQ6LOeca7h5l9CXvPv/Y/m5IS/4z0/Qnj7DKx9+Pf/jcx9ioFJtdGjOOddQ8y6hs+AEuj59I8f9mlj/Xx+nJdnP+VtfyZ987iOkqb8K2Dl37Jp/CR2g4ziW/ctNLD/LOOfOT1CKBzj7/ufzP786L99J75xz02J+JnRAHV0c95mbOH5dlXPv/kdaq7Dy7i7+dsP3Gh2ac841xLxN6ABqW8Lyq2/mxLX9vGjTp+got2A/HuBLd9zV6NCcc27WzeuEDqC2RRz/xR+zYvUBzv7lv7JocBHbvr2VWzY/3OjQnHNuVs37hA6g1gWc8JUfs+rEZzjr3s9xXP/x/Ojq29nyxIz8tsk55+akpkjoAGrt5KSv3kx31+Ose+ArrDi0is/+0wZ29Qw0OjTnnJsVTZPQAdTWyUlfv5k1Cx5kzbZv0t2zmg///bfoL8eNDs0552ZcUyV0gKCtgxXX3Mxzi79g1fYfcurek3jfR75DnKSNDs0552ZU0yV0gKC9g5XfuJHT7XZOfPI2Tn6yiw984nqyV84451xzasqEDhB0dLL6mzdyxsB/sGzXJo7f1sbHPnt7o8NyzrkZ07QJHSDs7OSUb93AGT3fYdH+zbRsqvClb/6y0WE559yMaOqEDhAuXMhp37ye03d9jc6Dj9Fz8y5+eNNDjQ7LOeem3aTeh543+vyPQAh81sw+PE65NwLfAl5kZhunLcopipYs5oxvfI/Km97AfdGf8fC3Aj75vc1Ya0JpSQedK49j5ZouTn9OF8sWtTQ6XOecOyoTJnRJIXAl8BqytkPvlrTBzDaPKtcJvBOYk7+7j5Yt44XXXkfypt9mX9u57Ft4In3tJ5D0dHLwsX3cf/s+7uNBLNwHrQdpbU9ZuGwBS08+gVVnrKF7xQlEYdNf0Djn5rHJnKGfA2wzs0cAJF0DvAHYPKrch4CPAJdPa4TTqLD8ONZ/8zvs+NJnOLhtE/HOnWj3IdJkMX1tJ9DXnnWH2k9koHUZu54J2HVfwgMbNhPoVsLCMxTbeliwULS3t1FauJCWJUtoP245C5efwMJlJ7GgvRVJjd5V59wxaDIJ/SRgR934TuDc+gKSzgZWmtkPJI2b0CVdClwKsGrVqmcf7TQoLF/OKZf/zYhp6eAg1SeeYODx7ex9ZDMHHv0pA49vZ3A3pJWFVIrHZ8m+7UT6Ks+nr2f0mXoM9ijiPlAfBAMQDkChCiUjbIkotrXR2rmI9iVdtC5ZStuShSxcvICFC1pY0F6gvRgRBl4ROOeO3qTuoR+JpAD4OPD2icqa2VXAVQDr16+fMw+FBy0tlE49ldKpp7LoFa88bH7S00P/44/xzLZ72P3wTzj4RA/VA2WSvhSrhCguIWslCduoFtqpRu1UC4uJC21Uo3bisEgM9APZ22X2Dg0BYGVgEFPWoTIWVrAwxgoxFAyKImgLiVpLFFtaaGlpp6W9k9aOhbR3LKVj0WLa21tpayvQ3hrRVgxpiUICryScO2ZMJqE/AaysG1+RT6vpBM4Abs1vNRwPbJB08Vz6YnQqwoUL6TzzLDrPPIs145QxM9K+PpL9+xnc8wy9zzzBoT1PMbD7XgZ372Zw70EqByqkA8KqBSwtAiVMLSRhC3HYShK1EIctxFErSdRBHLYSRy0kYQmUXRUYUM67rCXVKvB03tWCiZFVwSpAFVEFqhhVUAxKQAkWpCgwCFIIDUWgSASFgKAQEBUjopaIQkuRUmsLpbYSrW0ttLa00NrSRltbOy1t7RRbWii2tlJqb6PUUiQI/LsG5xphMgn9bmCtpJPJEvlbgd+rzTSzHqCrNi7pVuCvmiWZT5Ykwo4Owo4OiitXsoD1k1rOzLBKhbS/n7SvHxvoJ+3vJ+7vo9zbw2DvAcoH9zGw/wCDB/voPzRAuT8mLsfEsZHGkCTC0jDrLMIoZJ2KQAFTNmxBgSQokYZF0qBAqog0iLLhoEAahAAkeWzlI0Y+kHd7Dj8WaTWrVEiQxchioNbPpqE021LeN6XZcN6ZUggMAsOCFIKsTrOQ7GHbMIAgQGEIQYSiAMICQRhBFBFERYKogApFwqhIEBWJCkWCMBsvFAoUigVKhSLFYjZcKIREUUChEFAohFk/CikUs2nFQkghCggjr7Dc3DRhQjezWNJlwA1kjy1ebWb3S/ogsNHMNsx0kM1MEiqVCEolWLx4xLzOad6WmWHlMpWDe6kO9FDp76XS30vc30t1YB/lvkNU+gcZODRIeWCA8kCFeCCmWolJyilJ1bDYSKtgKZAKS4URYGkAZBnXLCT7qIQYUdZXCETZuLJpqFQ3L8SCkFQhpgBUPx5iwZTvDgIpMJh3U2BJti4zhOXrtbwbbzgbNwxUPy+vxDBEms+rTc+HZWhomGxYyuZLICGRVXRS9pkSENSGhYKsQyJQkB3+fNmsssznB0JBAIGyCjMflwRhgMKsEg2ikDAsEEQRYaFIGISEYUgUFgiirB9FEWEQoSgkCkPCIFs+jAKiMEABREFAGAYEoQhDEYUiDIJsOAoIAxGEQbabeYxZ2H4rcSxq1PtN1q9fbxs3HlMn8e4IzAyqVZJKhaQ8QFweIB4cJK4MkAwOEpcHqPYPEg/2U+3rJ6mWqZT7ScplknKZuFImrVRI4ipJtUparWBxQlqNsSTB4gTShDROsdQwE5ZASgAWkKYBRgAmUgvBAoz8csBCjHB4nBBMiCDLvQQIIcuzqgmyKXl5IQtAwpRVgCjARneMHOdI8xAoqwbyLJ+FMuZwLfll26/1TeHQrbx5x+oqREvrKtasoh2qIMcsM1ZlO7LizQyXMY0uM7YR1cyYlU42belzY9707nc++/0GJG0yszFvAUzHaY9zUyYJikWiYpGoo4NSowOaAZamEMdYHGOpQZpAmmbT0xRLssRDkpCmaVY5pTFpXCVOqiSVMmlcJq4OksSVrAJLKqR5BRbn/SSOSaoV0mpMEtcqt2w9aW37ZmBGmmbJK7W8kjPD0jxlmUixvJLLxvPFspyZ5JVj3mX51LJ5+XBtmeyiRNk0ssrQbLjSs1rlZ+SVTF4xariStKHLkCBPqXk5yCrJvHIbHg7qlhm1nVrqVf1yw5VjrcyI5VW/zqkZ3HH/lNcxFk/ozs0SBQEUi6hYbHQobgqG7moM1WyHD9tw4THLqFCYkdg8oTvn3LMwdP/+CGfqjbrD37B76JJ2A9uPcvEuxnq8Yu7w+KbG45u6uR6jx3f0VpvZsrFmNCyhT4WkjeN9KTAXeHxT4/FN3VyP0eObGfP0K27nnHOjeUJ3zrkmMV8T+lWNDmACHt/UeHxTN9dj9PhmwLy8h+6cc+5w8/UM3Tnn3CgNew69q6vLuru7G7V555yblzZt2rRnvMcWG5bQu7u78Xe5OOfcsyNp3N/vTOqWi6QLJW2RtE3SFeOUebOkzZLul/S1ow3WOefc0ZmWRqIlrQXeA7zEzPZLOm6mAnbOOTe2yZyhDzUSbWYVoNZIdL13AFea2X4AM9s1vWE655ybyGQS+liNRJ80qsxpwGmS7pB0p6QLpytA55xzkzNdX4pGwFrgArI2R2+TdKaZHagvJOlS4FKAVatWTdOmnXPOweTO0CdqJBqys/YNZlY1s0eBrWQJfgQzu8rM1pvZ+mXLxnzqxjnn3FGaTEIfaiRaUpGskejR7YheR3Z2jqQuslswj0xjnM455yYwYUI3sxioNRL9APCNWiPRki7Oi90A7JW0GbgFuNzM9s5U0M455w7njUQ759w8cqRGov1dLs451yQ8oTvnXJPwhO6cc03CE7pzzjUJT+jOOdckPKE751yT8ITunHNNwhO6c841CU/ozjnXJDyhO+dck/CE7pxzTcITunPONQlP6M451yQ8oTvnXJPwhO6cc01iUgld0oWStkjaJumKI5R7oySTNOa7ep1zzs2cCRO6pBC4ErgIWAdcImndGOU6gXcCd013kM455yY2mTP0c4BtZvaImVWAa4A3jFHuQ8BHgMFpjO8we3+5lUeuvZHyjidoVGtLzjk3F0WTKHMSsKNufCdwbn0BSWcDK83sB5IuH29Fki4FLgVYtWrVs48WuO+6X3Df08sIb7qHhX3fZ1lbPyd0t3HiC1fTfuY6CitXIumo1u2cc/PZZBL6EUkKgI8Db5+orJldBVwFWZuiR7O91b/1XLjtPnqfCtlfWM6WpJMtO4Uer7Lgy//B4oHHOW5JygmnLaHzjOfScvrpFLtXo8C//3XONbfJJPQngJV14yvyaTWdwBnArfmZ8fHABkkXm9m0twJ906+uZGdwI60npLQtN0pxOxxaR7T/uQxqLY8tfDmPKYTHUjrv3cGins+yqH87y5elLDx9DS3PfyGlNWtQGIKUdZD3lf1/9PS6edmkuvlDy04wnE2Y5qMxau3jrX6sGfntquG7VjY8YqOGIbu9daQqeNQmDrtKGi+4+vXXhXLYyFi31xSM/HsFwdDfSmJ4vDYtGC6nMIQwRHlHFHml7+a9yST0u4G1kk4mS+RvBX6vNtPMeoCu2rikW4G/molkDmCnPZ+bH76XwaRMmWr2z33ZVjh5KwBRUmR5bzcn9ZzK6n2nsnjB+eygwL1A27YnWbzxV3Qe+j5K40lvU2NlsgmvLyZ7AaIxB22SyV/UEq3lwzY8HfLx2tqOUPawcjZqHcPlhGUlpeE4VVsyyPcjX1rByP05QuUyYp8Om1+LYWjiiN7QPo2z3rHmjZxmGGACk5EG2arTIJ8WWDZdwgTI8qNg2fxaMPn0bKPZMkNbqC2TT0tVm86IcWprDobWmsdV20Ztg6P+nkPHYdQ8q+2/5Ucw76u27trJSkBa+zsG+fR8fv1wfcx1B3job5Htn4aPQ32ZoWlCBmYiO5y1/vDODu1uXnZ4mvI1jPz7Kd+v+ulDw7WPX35iYrKR+5gPG/nfOl8mrc3Lxy3/PKh2OIf/1MPxDsU3XE5DfwshM9pe/Sou+tP3M90mTOhmFku6DLgBCIGrzex+SR8ENprZhmmP6gjecd5lvOO8y2qxMZgM0l/tpz/uZyAeoL/az76BQzzds5d9B57mwP6fUXkmJdzTRulAF4c6ziWw82czZOecG6F9649nZL2TuoduZtcD14+a9r5xyl4w9bAmRxKtUSutUStLWTqpZdIk5dD+8hhX8IefUY/7EM0UH64xs/G/uD3SHZsRZ+1Wf+I6dMvC0vxcc8TJ9STLpjZ04geWz89WMnRCWLv1MnSro3ZCrro7WMO3rob2YfT40LEY2p3aXo0YH1nGRs6qGzh8PcPLHFbeRm5n5F2nw2/91I7B6HgtP0bZdBte79AFT37Wn9bFOHobo/dx1ISxPoNH/JvWtjHiMzByXv0ZOtTfXawN1Hq1v+Pwtsf73I7epxGjY/1tR30ehj5LGt5Gdqds7DKj129jHS+zEeMjjtuo2CazT/XrOdJzF0d8KCOfteI554xfZgqm/KXofBOEAQu6WhsdhnPOTTv/Fsg555qEJ3TnnGsSatSvLSXtBrYf5eJdwJ5pDGe6eXxT4/FN3VyP0eM7eqvNbNlYMxqW0KdC0kYzm7MvAPP4psbjm7q5HqPHNzP8lotzzjUJT+jOOdck5mtCv6rRAUzA45saj2/q5nqMHt8MmJf30J1zzh1uvp6hO+ecG2VOJ/SJmr6TVJJ0bT7/LkndsxjbSkm3SNos6X5J7xyjzAWSeiT9Mu/GfF3CDMb4mKR7820f9rI0Zf4pP3735O+1n63YnlN3XH4p6aCkd40qM+vHT9LVknZJuq9u2hJJN0p6KO8vHmfZP8zLPCTpD2cpto9KejD/+31X0qJxlj3iZ2GGY3y/pCfq/o6/Mc6yk2rqcgbiu7Yutsck/XKcZWflGE6Jmc3JjuxFYA8DpwBF4FfAulFl/gz413z4rcC1sxjfCcDZ+XAnsHWM+C4Avt/AY/gY0HWE+b8B/JDsDRMvBu5q4N/6abLnaxt6/IDzgbOB++qm/T1wRT58BfCRMZZbAjyS9xfnw4tnIbbXAlE+/JGxYpvMZ2GGY3w/2RtYJ/oMHPHf+0zFN2r+x4D3NfIYTqWby2fok2n67g3AF/PhbwGv0iw1V2RmT5nZz/PhXuABstad5pM3AF+yzJ3AIkknNCCOVwEPm9nR/tBs2pjZbcC+UZPrP2dfBH5rjEV/HbjRzPaZ2X7gRuDCmY7NzH5kZrV3Qd9J1l5Bw4xz/CZjsk1dTsmR4stzx5uBr0/3dmfLXE7oYzV9NzphDpXJP9Q9MMnXLk6j/FbPCxm7gezzJP1K0g8lnT6rgWXvkvuRpE3Kmv8bbTLHeDa8lfH/ETXy+NUsN7On8uGngeVjlJkLx/KPya64xjLRZ2GmXZbfFrp6nFtWc+H4vQx4xsweGmd+o4/hhOZyQp8XJHUA3wbeZWYHR83+OdlthLOATwHXzXJ4LzWzs4GLgD+XNOdeBC+pCFwMfHOM2Y0+foex7Np7zj0aJum9QAx8dZwijfws/AtwKvAC4Cmy2xpz0SUc+ex8zv97mssJfaKm70aUkRQBC4G9sxJdts0CWTL/qpl9Z/R8MztoZofy4euBgqSu0eVmipk9kfd3Ad8lu6ytN5ljPNMuAn5uZs+MntHo41fnmdqtqLy/a4wyDTuWkt4OvA74/bzCOcwkPgszxsyeMbPEzFLgM+Nsu6GfxTx//A5w7XhlGnkMJ2suJ/Shpu/ys7i3AqNbR9oA1J4m+F3gx+N9oKdbfr/tc8ADZvbxccocX7unL+kcsuM9KxWOpHZJnbVhsi/P7htVbAPwtvxplxcDPXW3FmbLuGdFjTx+o9R/zv4Q+N4YZW4AXitpcX5L4bX5tBkl6ULgr4GLzax/nDKT+SzMZIz138v89jjbnsy/95n0auBBM9s51sxGH8NJa/S3skfqyJ7C2Er27fd782kfJPvwArSQXapvA34GnDKLsb2U7NL7HuCXefcbwJ8Cf5qXuQy4n+wb+zuB/zaL8Z2Sb/dXeQy141cfn4Ar8+N7L7B+lv++7WQJemHdtIYeP7LK5SmgSnYf90/Ivpe5GXgIuAlYkpddD3y2btk/zj+L24A/mqXYtpHde659BmtPfZ0IXH+kz8IsHr8v55+ve8iS9AmjY8zHD/v3Phvx5dO/UPvc1ZVtyDGcSue/FHXOuSYxl2+5OOecexY8oTvnXJPwhO6cc03CE7pzzjUJT+jOOdckPKG7GSXp0Ayu+73K3nR5T/4GvHPz6e+S1HaU63y7pE8f5bIXSPp+3XpM0qvr5v9WPu13j2adUynjjg2e0N28JOk8sl9Hnm1mzyf7YUjtXSDvAo4qoU+ze8l+IFNzCdlzzM7NCE/oblbkv0b9qKT78ndKvyWffoKk2/Iz7PskvUxSKOkLdWX/1xirPAHYY2ZlADPbY2ZPSvoLsh+E3CLplnwb/yJpY342/4G6mF4k6b/yl3/9rPZLwLr5vynpp5K6JL02H/65pG/m7/CpvcP7QUk/J/vpeL3bgXMkFfLya8h+/FNb/6sk/SLfx6sllY60zvzXilfnsf5C0rS/jdDNb57Q3Wz5HbKXM51Fdjb90fwn4b8H3GBmtXm/zMudZGZnmNmZwOfHWN+PgJWStkr6Z0kvBzCzfwKeBF5hZq/Iy77XzNYDzwdeLun5+c/LrwXeadnLv14NDNRWLum3yd59XmuM4W+AV1v2cqaNwLsltZC9m+T1wK8Bx4+K0ch+WfrrZK+CHfope77sF4C35PsYAf9jgnW+l+z1FucAr8iPYfvYh9sdizyhu9nyUuDrlr2k6RngJ8CLyN7h8UeS3g+cadm75R8BTpH0qfxdJaPfYollL+36NeBSYDdwrbKXVI3lzfnZ7i+A04F1wHOAp8zs7nx9B234veKvBP438JuWvdv8xfkydyhrzeYPgdXAc4FHzewhy35y/ZUxtn0N2W2X0a8Ifk6+7NZ8/ItkjS8caZ2vBa7IY7iV7NUXq8bZZ3cM8oTuGsqyBgfOJ3uz3hckvS1PomeRJa0/BT6rrMm/WjNhf5ovm5jZrWb2/5C99+WNo9cv6WTgr4BX5ffaf0CWCI/kYbJWqE6rrYas8YoX5N06M/uTSe7fz4AzyVq62TpR+QkIeGNdHKvM7IEprtM1EU/obrbcDrwlvz++jCyJ/0zSarJGBT4DfBY4W9krcgMz+zbZrY6zzWxHXSL7V2Vtkq6tW/8LgFqLR71kCRlgAdAH9EhaTva6XoAtwAmSXgQgqVPZK1TJ1/NG4EvKGtW4E3iJpDV52XZJpwEPAt2STs2Xu2Scfb8C+L9GTduSL7smH/8DsquWI63zBuB/SkNvoHzhONtzx6ho4iLOTYvvAueRPeVhwF+b2dPKGlO+XFIVOAS8jaylms9Lqp1wvGeM9XUAn1LWKHJM9tbBWisyVwH/IelJM3uFpF+QJcodwB0AZlbJv5j9lKRWsvvnQ48YmtmDkn6f7G2erwfeDny99sUl8DdmtlVZyzU/+P/bu2MbhmEYCIDPUT1LFvAeGcVdFsgWgVMphdQYBjIAcTcACxVPQCKoqvpkNq3Lw+qqdftFaIxxVtWW5LkayZG5KfH7p+YjyZ7ktc7mnTnpA0li2yJAF65cAJoQ6ABNCHSAJgQ6QBMCHaAJgQ7QhEAHaEKgAzTxAwGXK48Eu3ovAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_D6zzsaHZNv",
        "outputId": "da3c309a-a3ef-4029-ac2b-cb03f518abaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install keras-metrics\n",
        "!cp \"drive/My Drive/Colab Notebooks/csic3.csv.zip\" .\n",
        "# importing required modules \n",
        "from zipfile import ZipFile \n",
        "\n",
        "# specifying the zip file name \n",
        "file_name = \"csic3.csv.zip\"\n",
        "\n",
        "# opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zip: \n",
        "  # printing all the contents of the zip file \n",
        "  zip.printdir() \n",
        "\n",
        "  # extracting all the files \n",
        "  print('Extracting all the files now...') \n",
        "  zip.extractall() \n",
        "  print('Done!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting keras-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.1.5->keras-metrics) (1.15.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n",
            "File Name                                             Modified             Size\n",
            "csic3.csv                                      2020-07-03 10:34:16     17333649\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}